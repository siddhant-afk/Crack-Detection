{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\nfrom pathlib import Path\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\n\nfrom sklearn.metrics import confusion_matrix, classification_report","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-14T12:48:23.378978Z","iopub.execute_input":"2023-05-14T12:48:23.379312Z","iopub.status.idle":"2023-05-14T12:48:45.620184Z","shell.execute_reply.started":"2023-05-14T12:48:23.379278Z","shell.execute_reply":"2023-05-14T12:48:45.618940Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"positive_dir = Path('../input/surface-crack-detection/Positive')\nnegative_dir = Path('../input/surface-crack-detection/Negative')","metadata":{"execution":{"iopub.status.busy":"2023-05-14T12:48:45.622763Z","iopub.execute_input":"2023-05-14T12:48:45.623902Z","iopub.status.idle":"2023-05-14T12:48:45.631176Z","shell.execute_reply.started":"2023-05-14T12:48:45.623857Z","shell.execute_reply":"2023-05-14T12:48:45.629958Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def generate_df(image_dir, label):\n    filepaths = pd.Series(list(image_dir.glob(r'*.jpg')), name='Filepath').astype(str)\n    labels = pd.Series(label, name='Label', index=filepaths.index)\n    df = pd.concat([filepaths, labels], axis=1)\n    return df","metadata":{"execution":{"iopub.status.busy":"2023-05-14T12:48:45.632731Z","iopub.execute_input":"2023-05-14T12:48:45.633425Z","iopub.status.idle":"2023-05-14T12:48:45.641543Z","shell.execute_reply.started":"2023-05-14T12:48:45.633370Z","shell.execute_reply":"2023-05-14T12:48:45.640327Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"positive_df = generate_df(positive_dir, label=\"POSITIVE\")\nnegative_df = generate_df(negative_dir, label=\"NEGATIVE\")\n\nall_df = pd.concat([positive_df, negative_df], axis=0).sample(frac=1.0, random_state=1).reset_index(drop=True)\nall_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-14T12:48:45.644627Z","iopub.execute_input":"2023-05-14T12:48:45.645529Z","iopub.status.idle":"2023-05-14T12:48:49.434827Z","shell.execute_reply.started":"2023-05-14T12:48:45.645478Z","shell.execute_reply":"2023-05-14T12:48:49.433758Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                            Filepath     Label\n0  ../input/surface-crack-detection/Positive/0574...  POSITIVE\n1  ../input/surface-crack-detection/Positive/1870...  POSITIVE\n2  ../input/surface-crack-detection/Positive/0967...  POSITIVE\n3  ../input/surface-crack-detection/Negative/0791...  NEGATIVE\n4  ../input/surface-crack-detection/Positive/1400...  POSITIVE","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Filepath</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>../input/surface-crack-detection/Positive/0574...</td>\n      <td>POSITIVE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>../input/surface-crack-detection/Positive/1870...</td>\n      <td>POSITIVE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>../input/surface-crack-detection/Positive/0967...</td>\n      <td>POSITIVE</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>../input/surface-crack-detection/Negative/0791...</td>\n      <td>NEGATIVE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>../input/surface-crack-detection/Positive/1400...</td>\n      <td>POSITIVE</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_df, test_df = train_test_split(\n    all_df,\n    train_size=0.8,\n    shuffle=True,\n    random_state=1\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T12:48:49.438167Z","iopub.execute_input":"2023-05-14T12:48:49.438502Z","iopub.status.idle":"2023-05-14T12:48:49.447615Z","shell.execute_reply.started":"2023-05-14T12:48:49.438465Z","shell.execute_reply":"2023-05-14T12:48:49.446570Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1./255,\n    validation_split=0.2\n)\n\ntest_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1./255\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T12:48:49.450422Z","iopub.execute_input":"2023-05-14T12:48:49.451587Z","iopub.status.idle":"2023-05-14T12:48:49.459463Z","shell.execute_reply.started":"2023-05-14T12:48:49.451555Z","shell.execute_reply":"2023-05-14T12:48:49.458416Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_data = train_gen.flow_from_dataframe(\n    train_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(120, 120),\n    color_mode='rgb',\n    class_mode='binary',\n    batch_size=32,\n    shuffle=True,\n    seed=42,\n    subset='training'\n)\n\nval_data = train_gen.flow_from_dataframe(\n    train_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(120, 120),\n    color_mode='rgb',\n    class_mode='binary',\n    batch_size=32,\n    shuffle=True,\n    seed=42,\n    subset='validation'\n)\n\ntest_data = train_gen.flow_from_dataframe(\n    test_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(120, 120),\n    color_mode='rgb',\n    class_mode='binary',\n    batch_size=32,\n    shuffle=False,\n    seed=42\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T12:48:49.461551Z","iopub.execute_input":"2023-05-14T12:48:49.461953Z","iopub.status.idle":"2023-05-14T12:53:26.591557Z","shell.execute_reply.started":"2023-05-14T12:48:49.461910Z","shell.execute_reply":"2023-05-14T12:53:26.590519Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Found 25600 validated image filenames belonging to 2 classes.\nFound 6400 validated image filenames belonging to 2 classes.\nFound 8000 validated image filenames belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.applications.inception_v3 import InceptionV3\n\ninception = InceptionV3(include_top = False,\n                       input_shape = (120,120,3),\n                       weights ='imagenet')","metadata":{"execution":{"iopub.status.busy":"2023-05-14T12:53:26.593032Z","iopub.execute_input":"2023-05-14T12:53:26.593519Z","iopub.status.idle":"2023-05-14T12:53:35.504823Z","shell.execute_reply.started":"2023-05-14T12:53:26.593472Z","shell.execute_reply":"2023-05-14T12:53:35.503668Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n87910968/87910968 [==============================] - 1s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"x = tf.keras.layers.Flatten()(inception.output)\noutputs = tf.keras.layers.Dense(1,activation='sigmoid')(x)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T12:53:35.508175Z","iopub.execute_input":"2023-05-14T12:53:35.509179Z","iopub.status.idle":"2023-05-14T12:53:35.537450Z","shell.execute_reply.started":"2023-05-14T12:53:35.509130Z","shell.execute_reply":"2023-05-14T12:53:35.536484Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.Model(inputs = inception.input,outputs=outputs)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-05-14T12:53:35.541288Z","iopub.execute_input":"2023-05-14T12:53:35.541592Z","iopub.status.idle":"2023-05-14T12:53:36.363136Z","shell.execute_reply.started":"2023-05-14T12:53:35.541562Z","shell.execute_reply":"2023-05-14T12:53:36.362260Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_1 (InputLayer)           [(None, 120, 120, 3  0           []                               \n                                )]                                                                \n                                                                                                  \n conv2d (Conv2D)                (None, 59, 59, 32)   864         ['input_1[0][0]']                \n                                                                                                  \n batch_normalization (BatchNorm  (None, 59, 59, 32)  96          ['conv2d[0][0]']                 \n alization)                                                                                       \n                                                                                                  \n activation (Activation)        (None, 59, 59, 32)   0           ['batch_normalization[0][0]']    \n                                                                                                  \n conv2d_1 (Conv2D)              (None, 57, 57, 32)   9216        ['activation[0][0]']             \n                                                                                                  \n batch_normalization_1 (BatchNo  (None, 57, 57, 32)  96          ['conv2d_1[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n activation_1 (Activation)      (None, 57, 57, 32)   0           ['batch_normalization_1[0][0]']  \n                                                                                                  \n conv2d_2 (Conv2D)              (None, 57, 57, 64)   18432       ['activation_1[0][0]']           \n                                                                                                  \n batch_normalization_2 (BatchNo  (None, 57, 57, 64)  192         ['conv2d_2[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n activation_2 (Activation)      (None, 57, 57, 64)   0           ['batch_normalization_2[0][0]']  \n                                                                                                  \n max_pooling2d (MaxPooling2D)   (None, 28, 28, 64)   0           ['activation_2[0][0]']           \n                                                                                                  \n conv2d_3 (Conv2D)              (None, 28, 28, 80)   5120        ['max_pooling2d[0][0]']          \n                                                                                                  \n batch_normalization_3 (BatchNo  (None, 28, 28, 80)  240         ['conv2d_3[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n activation_3 (Activation)      (None, 28, 28, 80)   0           ['batch_normalization_3[0][0]']  \n                                                                                                  \n conv2d_4 (Conv2D)              (None, 26, 26, 192)  138240      ['activation_3[0][0]']           \n                                                                                                  \n batch_normalization_4 (BatchNo  (None, 26, 26, 192)  576        ['conv2d_4[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n activation_4 (Activation)      (None, 26, 26, 192)  0           ['batch_normalization_4[0][0]']  \n                                                                                                  \n max_pooling2d_1 (MaxPooling2D)  (None, 12, 12, 192)  0          ['activation_4[0][0]']           \n                                                                                                  \n conv2d_8 (Conv2D)              (None, 12, 12, 64)   12288       ['max_pooling2d_1[0][0]']        \n                                                                                                  \n batch_normalization_8 (BatchNo  (None, 12, 12, 64)  192         ['conv2d_8[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n activation_8 (Activation)      (None, 12, 12, 64)   0           ['batch_normalization_8[0][0]']  \n                                                                                                  \n conv2d_6 (Conv2D)              (None, 12, 12, 48)   9216        ['max_pooling2d_1[0][0]']        \n                                                                                                  \n conv2d_9 (Conv2D)              (None, 12, 12, 96)   55296       ['activation_8[0][0]']           \n                                                                                                  \n batch_normalization_6 (BatchNo  (None, 12, 12, 48)  144         ['conv2d_6[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n batch_normalization_9 (BatchNo  (None, 12, 12, 96)  288         ['conv2d_9[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n activation_6 (Activation)      (None, 12, 12, 48)   0           ['batch_normalization_6[0][0]']  \n                                                                                                  \n activation_9 (Activation)      (None, 12, 12, 96)   0           ['batch_normalization_9[0][0]']  \n                                                                                                  \n average_pooling2d (AveragePool  (None, 12, 12, 192)  0          ['max_pooling2d_1[0][0]']        \n ing2D)                                                                                           \n                                                                                                  \n conv2d_5 (Conv2D)              (None, 12, 12, 64)   12288       ['max_pooling2d_1[0][0]']        \n                                                                                                  \n conv2d_7 (Conv2D)              (None, 12, 12, 64)   76800       ['activation_6[0][0]']           \n                                                                                                  \n conv2d_10 (Conv2D)             (None, 12, 12, 96)   82944       ['activation_9[0][0]']           \n                                                                                                  \n conv2d_11 (Conv2D)             (None, 12, 12, 32)   6144        ['average_pooling2d[0][0]']      \n                                                                                                  \n batch_normalization_5 (BatchNo  (None, 12, 12, 64)  192         ['conv2d_5[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n batch_normalization_7 (BatchNo  (None, 12, 12, 64)  192         ['conv2d_7[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n batch_normalization_10 (BatchN  (None, 12, 12, 96)  288         ['conv2d_10[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_11 (BatchN  (None, 12, 12, 32)  96          ['conv2d_11[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_5 (Activation)      (None, 12, 12, 64)   0           ['batch_normalization_5[0][0]']  \n                                                                                                  \n activation_7 (Activation)      (None, 12, 12, 64)   0           ['batch_normalization_7[0][0]']  \n                                                                                                  \n activation_10 (Activation)     (None, 12, 12, 96)   0           ['batch_normalization_10[0][0]'] \n                                                                                                  \n activation_11 (Activation)     (None, 12, 12, 32)   0           ['batch_normalization_11[0][0]'] \n                                                                                                  \n mixed0 (Concatenate)           (None, 12, 12, 256)  0           ['activation_5[0][0]',           \n                                                                  'activation_7[0][0]',           \n                                                                  'activation_10[0][0]',          \n                                                                  'activation_11[0][0]']          \n                                                                                                  \n conv2d_15 (Conv2D)             (None, 12, 12, 64)   16384       ['mixed0[0][0]']                 \n                                                                                                  \n batch_normalization_15 (BatchN  (None, 12, 12, 64)  192         ['conv2d_15[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_15 (Activation)     (None, 12, 12, 64)   0           ['batch_normalization_15[0][0]'] \n                                                                                                  \n conv2d_13 (Conv2D)             (None, 12, 12, 48)   12288       ['mixed0[0][0]']                 \n                                                                                                  \n conv2d_16 (Conv2D)             (None, 12, 12, 96)   55296       ['activation_15[0][0]']          \n                                                                                                  \n batch_normalization_13 (BatchN  (None, 12, 12, 48)  144         ['conv2d_13[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_16 (BatchN  (None, 12, 12, 96)  288         ['conv2d_16[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_13 (Activation)     (None, 12, 12, 48)   0           ['batch_normalization_13[0][0]'] \n                                                                                                  \n activation_16 (Activation)     (None, 12, 12, 96)   0           ['batch_normalization_16[0][0]'] \n                                                                                                  \n average_pooling2d_1 (AveragePo  (None, 12, 12, 256)  0          ['mixed0[0][0]']                 \n oling2D)                                                                                         \n                                                                                                  \n conv2d_12 (Conv2D)             (None, 12, 12, 64)   16384       ['mixed0[0][0]']                 \n                                                                                                  \n conv2d_14 (Conv2D)             (None, 12, 12, 64)   76800       ['activation_13[0][0]']          \n                                                                                                  \n conv2d_17 (Conv2D)             (None, 12, 12, 96)   82944       ['activation_16[0][0]']          \n                                                                                                  \n conv2d_18 (Conv2D)             (None, 12, 12, 64)   16384       ['average_pooling2d_1[0][0]']    \n                                                                                                  \n batch_normalization_12 (BatchN  (None, 12, 12, 64)  192         ['conv2d_12[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_14 (BatchN  (None, 12, 12, 64)  192         ['conv2d_14[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_17 (BatchN  (None, 12, 12, 96)  288         ['conv2d_17[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_18 (BatchN  (None, 12, 12, 64)  192         ['conv2d_18[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_12 (Activation)     (None, 12, 12, 64)   0           ['batch_normalization_12[0][0]'] \n                                                                                                  \n activation_14 (Activation)     (None, 12, 12, 64)   0           ['batch_normalization_14[0][0]'] \n                                                                                                  \n activation_17 (Activation)     (None, 12, 12, 96)   0           ['batch_normalization_17[0][0]'] \n                                                                                                  \n activation_18 (Activation)     (None, 12, 12, 64)   0           ['batch_normalization_18[0][0]'] \n                                                                                                  \n mixed1 (Concatenate)           (None, 12, 12, 288)  0           ['activation_12[0][0]',          \n                                                                  'activation_14[0][0]',          \n                                                                  'activation_17[0][0]',          \n                                                                  'activation_18[0][0]']          \n                                                                                                  \n conv2d_22 (Conv2D)             (None, 12, 12, 64)   18432       ['mixed1[0][0]']                 \n                                                                                                  \n batch_normalization_22 (BatchN  (None, 12, 12, 64)  192         ['conv2d_22[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_22 (Activation)     (None, 12, 12, 64)   0           ['batch_normalization_22[0][0]'] \n                                                                                                  \n conv2d_20 (Conv2D)             (None, 12, 12, 48)   13824       ['mixed1[0][0]']                 \n                                                                                                  \n conv2d_23 (Conv2D)             (None, 12, 12, 96)   55296       ['activation_22[0][0]']          \n                                                                                                  \n batch_normalization_20 (BatchN  (None, 12, 12, 48)  144         ['conv2d_20[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_23 (BatchN  (None, 12, 12, 96)  288         ['conv2d_23[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_20 (Activation)     (None, 12, 12, 48)   0           ['batch_normalization_20[0][0]'] \n                                                                                                  \n activation_23 (Activation)     (None, 12, 12, 96)   0           ['batch_normalization_23[0][0]'] \n                                                                                                  \n average_pooling2d_2 (AveragePo  (None, 12, 12, 288)  0          ['mixed1[0][0]']                 \n oling2D)                                                                                         \n                                                                                                  \n conv2d_19 (Conv2D)             (None, 12, 12, 64)   18432       ['mixed1[0][0]']                 \n                                                                                                  \n conv2d_21 (Conv2D)             (None, 12, 12, 64)   76800       ['activation_20[0][0]']          \n                                                                                                  \n conv2d_24 (Conv2D)             (None, 12, 12, 96)   82944       ['activation_23[0][0]']          \n                                                                                                  \n conv2d_25 (Conv2D)             (None, 12, 12, 64)   18432       ['average_pooling2d_2[0][0]']    \n                                                                                                  \n batch_normalization_19 (BatchN  (None, 12, 12, 64)  192         ['conv2d_19[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_21 (BatchN  (None, 12, 12, 64)  192         ['conv2d_21[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_24 (BatchN  (None, 12, 12, 96)  288         ['conv2d_24[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_25 (BatchN  (None, 12, 12, 64)  192         ['conv2d_25[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_19 (Activation)     (None, 12, 12, 64)   0           ['batch_normalization_19[0][0]'] \n                                                                                                  \n activation_21 (Activation)     (None, 12, 12, 64)   0           ['batch_normalization_21[0][0]'] \n                                                                                                  \n activation_24 (Activation)     (None, 12, 12, 96)   0           ['batch_normalization_24[0][0]'] \n                                                                                                  \n activation_25 (Activation)     (None, 12, 12, 64)   0           ['batch_normalization_25[0][0]'] \n                                                                                                  \n mixed2 (Concatenate)           (None, 12, 12, 288)  0           ['activation_19[0][0]',          \n                                                                  'activation_21[0][0]',          \n                                                                  'activation_24[0][0]',          \n                                                                  'activation_25[0][0]']          \n                                                                                                  \n conv2d_27 (Conv2D)             (None, 12, 12, 64)   18432       ['mixed2[0][0]']                 \n                                                                                                  \n batch_normalization_27 (BatchN  (None, 12, 12, 64)  192         ['conv2d_27[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_27 (Activation)     (None, 12, 12, 64)   0           ['batch_normalization_27[0][0]'] \n                                                                                                  \n conv2d_28 (Conv2D)             (None, 12, 12, 96)   55296       ['activation_27[0][0]']          \n                                                                                                  \n batch_normalization_28 (BatchN  (None, 12, 12, 96)  288         ['conv2d_28[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_28 (Activation)     (None, 12, 12, 96)   0           ['batch_normalization_28[0][0]'] \n                                                                                                  \n conv2d_26 (Conv2D)             (None, 5, 5, 384)    995328      ['mixed2[0][0]']                 \n                                                                                                  \n conv2d_29 (Conv2D)             (None, 5, 5, 96)     82944       ['activation_28[0][0]']          \n                                                                                                  \n batch_normalization_26 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_26[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_29 (BatchN  (None, 5, 5, 96)    288         ['conv2d_29[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_26 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_26[0][0]'] \n                                                                                                  \n activation_29 (Activation)     (None, 5, 5, 96)     0           ['batch_normalization_29[0][0]'] \n                                                                                                  \n max_pooling2d_2 (MaxPooling2D)  (None, 5, 5, 288)   0           ['mixed2[0][0]']                 \n                                                                                                  \n mixed3 (Concatenate)           (None, 5, 5, 768)    0           ['activation_26[0][0]',          \n                                                                  'activation_29[0][0]',          \n                                                                  'max_pooling2d_2[0][0]']        \n                                                                                                  \n conv2d_34 (Conv2D)             (None, 5, 5, 128)    98304       ['mixed3[0][0]']                 \n                                                                                                  \n batch_normalization_34 (BatchN  (None, 5, 5, 128)   384         ['conv2d_34[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_34 (Activation)     (None, 5, 5, 128)    0           ['batch_normalization_34[0][0]'] \n                                                                                                  \n conv2d_35 (Conv2D)             (None, 5, 5, 128)    114688      ['activation_34[0][0]']          \n                                                                                                  \n batch_normalization_35 (BatchN  (None, 5, 5, 128)   384         ['conv2d_35[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_35 (Activation)     (None, 5, 5, 128)    0           ['batch_normalization_35[0][0]'] \n                                                                                                  \n conv2d_31 (Conv2D)             (None, 5, 5, 128)    98304       ['mixed3[0][0]']                 \n                                                                                                  \n conv2d_36 (Conv2D)             (None, 5, 5, 128)    114688      ['activation_35[0][0]']          \n                                                                                                  \n batch_normalization_31 (BatchN  (None, 5, 5, 128)   384         ['conv2d_31[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_36 (BatchN  (None, 5, 5, 128)   384         ['conv2d_36[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_31 (Activation)     (None, 5, 5, 128)    0           ['batch_normalization_31[0][0]'] \n                                                                                                  \n activation_36 (Activation)     (None, 5, 5, 128)    0           ['batch_normalization_36[0][0]'] \n                                                                                                  \n conv2d_32 (Conv2D)             (None, 5, 5, 128)    114688      ['activation_31[0][0]']          \n                                                                                                  \n conv2d_37 (Conv2D)             (None, 5, 5, 128)    114688      ['activation_36[0][0]']          \n                                                                                                  \n batch_normalization_32 (BatchN  (None, 5, 5, 128)   384         ['conv2d_32[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_37 (BatchN  (None, 5, 5, 128)   384         ['conv2d_37[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_32 (Activation)     (None, 5, 5, 128)    0           ['batch_normalization_32[0][0]'] \n                                                                                                  \n activation_37 (Activation)     (None, 5, 5, 128)    0           ['batch_normalization_37[0][0]'] \n                                                                                                  \n average_pooling2d_3 (AveragePo  (None, 5, 5, 768)   0           ['mixed3[0][0]']                 \n oling2D)                                                                                         \n                                                                                                  \n conv2d_30 (Conv2D)             (None, 5, 5, 192)    147456      ['mixed3[0][0]']                 \n                                                                                                  \n conv2d_33 (Conv2D)             (None, 5, 5, 192)    172032      ['activation_32[0][0]']          \n                                                                                                  \n conv2d_38 (Conv2D)             (None, 5, 5, 192)    172032      ['activation_37[0][0]']          \n                                                                                                  \n conv2d_39 (Conv2D)             (None, 5, 5, 192)    147456      ['average_pooling2d_3[0][0]']    \n                                                                                                  \n batch_normalization_30 (BatchN  (None, 5, 5, 192)   576         ['conv2d_30[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_33 (BatchN  (None, 5, 5, 192)   576         ['conv2d_33[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_38 (BatchN  (None, 5, 5, 192)   576         ['conv2d_38[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_39 (BatchN  (None, 5, 5, 192)   576         ['conv2d_39[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_30 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_30[0][0]'] \n                                                                                                  \n activation_33 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_33[0][0]'] \n                                                                                                  \n activation_38 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_38[0][0]'] \n                                                                                                  \n activation_39 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_39[0][0]'] \n                                                                                                  \n mixed4 (Concatenate)           (None, 5, 5, 768)    0           ['activation_30[0][0]',          \n                                                                  'activation_33[0][0]',          \n                                                                  'activation_38[0][0]',          \n                                                                  'activation_39[0][0]']          \n                                                                                                  \n conv2d_44 (Conv2D)             (None, 5, 5, 160)    122880      ['mixed4[0][0]']                 \n                                                                                                  \n batch_normalization_44 (BatchN  (None, 5, 5, 160)   480         ['conv2d_44[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_44 (Activation)     (None, 5, 5, 160)    0           ['batch_normalization_44[0][0]'] \n                                                                                                  \n conv2d_45 (Conv2D)             (None, 5, 5, 160)    179200      ['activation_44[0][0]']          \n                                                                                                  \n batch_normalization_45 (BatchN  (None, 5, 5, 160)   480         ['conv2d_45[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_45 (Activation)     (None, 5, 5, 160)    0           ['batch_normalization_45[0][0]'] \n                                                                                                  \n conv2d_41 (Conv2D)             (None, 5, 5, 160)    122880      ['mixed4[0][0]']                 \n                                                                                                  \n conv2d_46 (Conv2D)             (None, 5, 5, 160)    179200      ['activation_45[0][0]']          \n                                                                                                  \n batch_normalization_41 (BatchN  (None, 5, 5, 160)   480         ['conv2d_41[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_46 (BatchN  (None, 5, 5, 160)   480         ['conv2d_46[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_41 (Activation)     (None, 5, 5, 160)    0           ['batch_normalization_41[0][0]'] \n                                                                                                  \n activation_46 (Activation)     (None, 5, 5, 160)    0           ['batch_normalization_46[0][0]'] \n                                                                                                  \n conv2d_42 (Conv2D)             (None, 5, 5, 160)    179200      ['activation_41[0][0]']          \n                                                                                                  \n conv2d_47 (Conv2D)             (None, 5, 5, 160)    179200      ['activation_46[0][0]']          \n                                                                                                  \n batch_normalization_42 (BatchN  (None, 5, 5, 160)   480         ['conv2d_42[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_47 (BatchN  (None, 5, 5, 160)   480         ['conv2d_47[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_42 (Activation)     (None, 5, 5, 160)    0           ['batch_normalization_42[0][0]'] \n                                                                                                  \n activation_47 (Activation)     (None, 5, 5, 160)    0           ['batch_normalization_47[0][0]'] \n                                                                                                  \n average_pooling2d_4 (AveragePo  (None, 5, 5, 768)   0           ['mixed4[0][0]']                 \n oling2D)                                                                                         \n                                                                                                  \n conv2d_40 (Conv2D)             (None, 5, 5, 192)    147456      ['mixed4[0][0]']                 \n                                                                                                  \n conv2d_43 (Conv2D)             (None, 5, 5, 192)    215040      ['activation_42[0][0]']          \n                                                                                                  \n conv2d_48 (Conv2D)             (None, 5, 5, 192)    215040      ['activation_47[0][0]']          \n                                                                                                  \n conv2d_49 (Conv2D)             (None, 5, 5, 192)    147456      ['average_pooling2d_4[0][0]']    \n                                                                                                  \n batch_normalization_40 (BatchN  (None, 5, 5, 192)   576         ['conv2d_40[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_43 (BatchN  (None, 5, 5, 192)   576         ['conv2d_43[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_48 (BatchN  (None, 5, 5, 192)   576         ['conv2d_48[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_49 (BatchN  (None, 5, 5, 192)   576         ['conv2d_49[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_40 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_40[0][0]'] \n                                                                                                  \n activation_43 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_43[0][0]'] \n                                                                                                  \n activation_48 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_48[0][0]'] \n                                                                                                  \n activation_49 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_49[0][0]'] \n                                                                                                  \n mixed5 (Concatenate)           (None, 5, 5, 768)    0           ['activation_40[0][0]',          \n                                                                  'activation_43[0][0]',          \n                                                                  'activation_48[0][0]',          \n                                                                  'activation_49[0][0]']          \n                                                                                                  \n conv2d_54 (Conv2D)             (None, 5, 5, 160)    122880      ['mixed5[0][0]']                 \n                                                                                                  \n batch_normalization_54 (BatchN  (None, 5, 5, 160)   480         ['conv2d_54[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_54 (Activation)     (None, 5, 5, 160)    0           ['batch_normalization_54[0][0]'] \n                                                                                                  \n conv2d_55 (Conv2D)             (None, 5, 5, 160)    179200      ['activation_54[0][0]']          \n                                                                                                  \n batch_normalization_55 (BatchN  (None, 5, 5, 160)   480         ['conv2d_55[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_55 (Activation)     (None, 5, 5, 160)    0           ['batch_normalization_55[0][0]'] \n                                                                                                  \n conv2d_51 (Conv2D)             (None, 5, 5, 160)    122880      ['mixed5[0][0]']                 \n                                                                                                  \n conv2d_56 (Conv2D)             (None, 5, 5, 160)    179200      ['activation_55[0][0]']          \n                                                                                                  \n batch_normalization_51 (BatchN  (None, 5, 5, 160)   480         ['conv2d_51[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_56 (BatchN  (None, 5, 5, 160)   480         ['conv2d_56[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_51 (Activation)     (None, 5, 5, 160)    0           ['batch_normalization_51[0][0]'] \n                                                                                                  \n activation_56 (Activation)     (None, 5, 5, 160)    0           ['batch_normalization_56[0][0]'] \n                                                                                                  \n conv2d_52 (Conv2D)             (None, 5, 5, 160)    179200      ['activation_51[0][0]']          \n                                                                                                  \n conv2d_57 (Conv2D)             (None, 5, 5, 160)    179200      ['activation_56[0][0]']          \n                                                                                                  \n batch_normalization_52 (BatchN  (None, 5, 5, 160)   480         ['conv2d_52[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_57 (BatchN  (None, 5, 5, 160)   480         ['conv2d_57[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_52 (Activation)     (None, 5, 5, 160)    0           ['batch_normalization_52[0][0]'] \n                                                                                                  \n activation_57 (Activation)     (None, 5, 5, 160)    0           ['batch_normalization_57[0][0]'] \n                                                                                                  \n average_pooling2d_5 (AveragePo  (None, 5, 5, 768)   0           ['mixed5[0][0]']                 \n oling2D)                                                                                         \n                                                                                                  \n conv2d_50 (Conv2D)             (None, 5, 5, 192)    147456      ['mixed5[0][0]']                 \n                                                                                                  \n conv2d_53 (Conv2D)             (None, 5, 5, 192)    215040      ['activation_52[0][0]']          \n                                                                                                  \n conv2d_58 (Conv2D)             (None, 5, 5, 192)    215040      ['activation_57[0][0]']          \n                                                                                                  \n conv2d_59 (Conv2D)             (None, 5, 5, 192)    147456      ['average_pooling2d_5[0][0]']    \n                                                                                                  \n batch_normalization_50 (BatchN  (None, 5, 5, 192)   576         ['conv2d_50[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_53 (BatchN  (None, 5, 5, 192)   576         ['conv2d_53[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_58 (BatchN  (None, 5, 5, 192)   576         ['conv2d_58[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_59 (BatchN  (None, 5, 5, 192)   576         ['conv2d_59[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_50 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_50[0][0]'] \n                                                                                                  \n activation_53 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_53[0][0]'] \n                                                                                                  \n activation_58 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_58[0][0]'] \n                                                                                                  \n activation_59 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_59[0][0]'] \n                                                                                                  \n mixed6 (Concatenate)           (None, 5, 5, 768)    0           ['activation_50[0][0]',          \n                                                                  'activation_53[0][0]',          \n                                                                  'activation_58[0][0]',          \n                                                                  'activation_59[0][0]']          \n                                                                                                  \n conv2d_64 (Conv2D)             (None, 5, 5, 192)    147456      ['mixed6[0][0]']                 \n                                                                                                  \n batch_normalization_64 (BatchN  (None, 5, 5, 192)   576         ['conv2d_64[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_64 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_64[0][0]'] \n                                                                                                  \n conv2d_65 (Conv2D)             (None, 5, 5, 192)    258048      ['activation_64[0][0]']          \n                                                                                                  \n batch_normalization_65 (BatchN  (None, 5, 5, 192)   576         ['conv2d_65[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_65 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_65[0][0]'] \n                                                                                                  \n conv2d_61 (Conv2D)             (None, 5, 5, 192)    147456      ['mixed6[0][0]']                 \n                                                                                                  \n conv2d_66 (Conv2D)             (None, 5, 5, 192)    258048      ['activation_65[0][0]']          \n                                                                                                  \n batch_normalization_61 (BatchN  (None, 5, 5, 192)   576         ['conv2d_61[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_66 (BatchN  (None, 5, 5, 192)   576         ['conv2d_66[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_61 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_61[0][0]'] \n                                                                                                  \n activation_66 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_66[0][0]'] \n                                                                                                  \n conv2d_62 (Conv2D)             (None, 5, 5, 192)    258048      ['activation_61[0][0]']          \n                                                                                                  \n conv2d_67 (Conv2D)             (None, 5, 5, 192)    258048      ['activation_66[0][0]']          \n                                                                                                  \n batch_normalization_62 (BatchN  (None, 5, 5, 192)   576         ['conv2d_62[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_67 (BatchN  (None, 5, 5, 192)   576         ['conv2d_67[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_62 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_62[0][0]'] \n                                                                                                  \n activation_67 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_67[0][0]'] \n                                                                                                  \n average_pooling2d_6 (AveragePo  (None, 5, 5, 768)   0           ['mixed6[0][0]']                 \n oling2D)                                                                                         \n                                                                                                  \n conv2d_60 (Conv2D)             (None, 5, 5, 192)    147456      ['mixed6[0][0]']                 \n                                                                                                  \n conv2d_63 (Conv2D)             (None, 5, 5, 192)    258048      ['activation_62[0][0]']          \n                                                                                                  \n conv2d_68 (Conv2D)             (None, 5, 5, 192)    258048      ['activation_67[0][0]']          \n                                                                                                  \n conv2d_69 (Conv2D)             (None, 5, 5, 192)    147456      ['average_pooling2d_6[0][0]']    \n                                                                                                  \n batch_normalization_60 (BatchN  (None, 5, 5, 192)   576         ['conv2d_60[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_63 (BatchN  (None, 5, 5, 192)   576         ['conv2d_63[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_68 (BatchN  (None, 5, 5, 192)   576         ['conv2d_68[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_69 (BatchN  (None, 5, 5, 192)   576         ['conv2d_69[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_60 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_60[0][0]'] \n                                                                                                  \n activation_63 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_63[0][0]'] \n                                                                                                  \n activation_68 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_68[0][0]'] \n                                                                                                  \n activation_69 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_69[0][0]'] \n                                                                                                  \n mixed7 (Concatenate)           (None, 5, 5, 768)    0           ['activation_60[0][0]',          \n                                                                  'activation_63[0][0]',          \n                                                                  'activation_68[0][0]',          \n                                                                  'activation_69[0][0]']          \n                                                                                                  \n conv2d_72 (Conv2D)             (None, 5, 5, 192)    147456      ['mixed7[0][0]']                 \n                                                                                                  \n batch_normalization_72 (BatchN  (None, 5, 5, 192)   576         ['conv2d_72[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_72 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_72[0][0]'] \n                                                                                                  \n conv2d_73 (Conv2D)             (None, 5, 5, 192)    258048      ['activation_72[0][0]']          \n                                                                                                  \n batch_normalization_73 (BatchN  (None, 5, 5, 192)   576         ['conv2d_73[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_73 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_73[0][0]'] \n                                                                                                  \n conv2d_70 (Conv2D)             (None, 5, 5, 192)    147456      ['mixed7[0][0]']                 \n                                                                                                  \n conv2d_74 (Conv2D)             (None, 5, 5, 192)    258048      ['activation_73[0][0]']          \n                                                                                                  \n batch_normalization_70 (BatchN  (None, 5, 5, 192)   576         ['conv2d_70[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_74 (BatchN  (None, 5, 5, 192)   576         ['conv2d_74[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_70 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_70[0][0]'] \n                                                                                                  \n activation_74 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_74[0][0]'] \n                                                                                                  \n conv2d_71 (Conv2D)             (None, 2, 2, 320)    552960      ['activation_70[0][0]']          \n                                                                                                  \n conv2d_75 (Conv2D)             (None, 2, 2, 192)    331776      ['activation_74[0][0]']          \n                                                                                                  \n batch_normalization_71 (BatchN  (None, 2, 2, 320)   960         ['conv2d_71[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_75 (BatchN  (None, 2, 2, 192)   576         ['conv2d_75[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_71 (Activation)     (None, 2, 2, 320)    0           ['batch_normalization_71[0][0]'] \n                                                                                                  \n activation_75 (Activation)     (None, 2, 2, 192)    0           ['batch_normalization_75[0][0]'] \n                                                                                                  \n max_pooling2d_3 (MaxPooling2D)  (None, 2, 2, 768)   0           ['mixed7[0][0]']                 \n                                                                                                  \n mixed8 (Concatenate)           (None, 2, 2, 1280)   0           ['activation_71[0][0]',          \n                                                                  'activation_75[0][0]',          \n                                                                  'max_pooling2d_3[0][0]']        \n                                                                                                  \n conv2d_80 (Conv2D)             (None, 2, 2, 448)    573440      ['mixed8[0][0]']                 \n                                                                                                  \n batch_normalization_80 (BatchN  (None, 2, 2, 448)   1344        ['conv2d_80[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_80 (Activation)     (None, 2, 2, 448)    0           ['batch_normalization_80[0][0]'] \n                                                                                                  \n conv2d_77 (Conv2D)             (None, 2, 2, 384)    491520      ['mixed8[0][0]']                 \n                                                                                                  \n conv2d_81 (Conv2D)             (None, 2, 2, 384)    1548288     ['activation_80[0][0]']          \n                                                                                                  \n batch_normalization_77 (BatchN  (None, 2, 2, 384)   1152        ['conv2d_77[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_81 (BatchN  (None, 2, 2, 384)   1152        ['conv2d_81[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_77 (Activation)     (None, 2, 2, 384)    0           ['batch_normalization_77[0][0]'] \n                                                                                                  \n activation_81 (Activation)     (None, 2, 2, 384)    0           ['batch_normalization_81[0][0]'] \n                                                                                                  \n conv2d_78 (Conv2D)             (None, 2, 2, 384)    442368      ['activation_77[0][0]']          \n                                                                                                  \n conv2d_79 (Conv2D)             (None, 2, 2, 384)    442368      ['activation_77[0][0]']          \n                                                                                                  \n conv2d_82 (Conv2D)             (None, 2, 2, 384)    442368      ['activation_81[0][0]']          \n                                                                                                  \n conv2d_83 (Conv2D)             (None, 2, 2, 384)    442368      ['activation_81[0][0]']          \n                                                                                                  \n average_pooling2d_7 (AveragePo  (None, 2, 2, 1280)  0           ['mixed8[0][0]']                 \n oling2D)                                                                                         \n                                                                                                  \n conv2d_76 (Conv2D)             (None, 2, 2, 320)    409600      ['mixed8[0][0]']                 \n                                                                                                  \n batch_normalization_78 (BatchN  (None, 2, 2, 384)   1152        ['conv2d_78[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_79 (BatchN  (None, 2, 2, 384)   1152        ['conv2d_79[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_82 (BatchN  (None, 2, 2, 384)   1152        ['conv2d_82[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_83 (BatchN  (None, 2, 2, 384)   1152        ['conv2d_83[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n conv2d_84 (Conv2D)             (None, 2, 2, 192)    245760      ['average_pooling2d_7[0][0]']    \n                                                                                                  \n batch_normalization_76 (BatchN  (None, 2, 2, 320)   960         ['conv2d_76[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_78 (Activation)     (None, 2, 2, 384)    0           ['batch_normalization_78[0][0]'] \n                                                                                                  \n activation_79 (Activation)     (None, 2, 2, 384)    0           ['batch_normalization_79[0][0]'] \n                                                                                                  \n activation_82 (Activation)     (None, 2, 2, 384)    0           ['batch_normalization_82[0][0]'] \n                                                                                                  \n activation_83 (Activation)     (None, 2, 2, 384)    0           ['batch_normalization_83[0][0]'] \n                                                                                                  \n batch_normalization_84 (BatchN  (None, 2, 2, 192)   576         ['conv2d_84[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_76 (Activation)     (None, 2, 2, 320)    0           ['batch_normalization_76[0][0]'] \n                                                                                                  \n mixed9_0 (Concatenate)         (None, 2, 2, 768)    0           ['activation_78[0][0]',          \n                                                                  'activation_79[0][0]']          \n                                                                                                  \n concatenate (Concatenate)      (None, 2, 2, 768)    0           ['activation_82[0][0]',          \n                                                                  'activation_83[0][0]']          \n                                                                                                  \n activation_84 (Activation)     (None, 2, 2, 192)    0           ['batch_normalization_84[0][0]'] \n                                                                                                  \n mixed9 (Concatenate)           (None, 2, 2, 2048)   0           ['activation_76[0][0]',          \n                                                                  'mixed9_0[0][0]',               \n                                                                  'concatenate[0][0]',            \n                                                                  'activation_84[0][0]']          \n                                                                                                  \n conv2d_89 (Conv2D)             (None, 2, 2, 448)    917504      ['mixed9[0][0]']                 \n                                                                                                  \n batch_normalization_89 (BatchN  (None, 2, 2, 448)   1344        ['conv2d_89[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_89 (Activation)     (None, 2, 2, 448)    0           ['batch_normalization_89[0][0]'] \n                                                                                                  \n conv2d_86 (Conv2D)             (None, 2, 2, 384)    786432      ['mixed9[0][0]']                 \n                                                                                                  \n conv2d_90 (Conv2D)             (None, 2, 2, 384)    1548288     ['activation_89[0][0]']          \n                                                                                                  \n batch_normalization_86 (BatchN  (None, 2, 2, 384)   1152        ['conv2d_86[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_90 (BatchN  (None, 2, 2, 384)   1152        ['conv2d_90[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_86 (Activation)     (None, 2, 2, 384)    0           ['batch_normalization_86[0][0]'] \n                                                                                                  \n activation_90 (Activation)     (None, 2, 2, 384)    0           ['batch_normalization_90[0][0]'] \n                                                                                                  \n conv2d_87 (Conv2D)             (None, 2, 2, 384)    442368      ['activation_86[0][0]']          \n                                                                                                  \n conv2d_88 (Conv2D)             (None, 2, 2, 384)    442368      ['activation_86[0][0]']          \n                                                                                                  \n conv2d_91 (Conv2D)             (None, 2, 2, 384)    442368      ['activation_90[0][0]']          \n                                                                                                  \n conv2d_92 (Conv2D)             (None, 2, 2, 384)    442368      ['activation_90[0][0]']          \n                                                                                                  \n average_pooling2d_8 (AveragePo  (None, 2, 2, 2048)  0           ['mixed9[0][0]']                 \n oling2D)                                                                                         \n                                                                                                  \n conv2d_85 (Conv2D)             (None, 2, 2, 320)    655360      ['mixed9[0][0]']                 \n                                                                                                  \n batch_normalization_87 (BatchN  (None, 2, 2, 384)   1152        ['conv2d_87[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_88 (BatchN  (None, 2, 2, 384)   1152        ['conv2d_88[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_91 (BatchN  (None, 2, 2, 384)   1152        ['conv2d_91[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_92 (BatchN  (None, 2, 2, 384)   1152        ['conv2d_92[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n conv2d_93 (Conv2D)             (None, 2, 2, 192)    393216      ['average_pooling2d_8[0][0]']    \n                                                                                                  \n batch_normalization_85 (BatchN  (None, 2, 2, 320)   960         ['conv2d_85[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_87 (Activation)     (None, 2, 2, 384)    0           ['batch_normalization_87[0][0]'] \n                                                                                                  \n activation_88 (Activation)     (None, 2, 2, 384)    0           ['batch_normalization_88[0][0]'] \n                                                                                                  \n activation_91 (Activation)     (None, 2, 2, 384)    0           ['batch_normalization_91[0][0]'] \n                                                                                                  \n activation_92 (Activation)     (None, 2, 2, 384)    0           ['batch_normalization_92[0][0]'] \n                                                                                                  \n batch_normalization_93 (BatchN  (None, 2, 2, 192)   576         ['conv2d_93[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_85 (Activation)     (None, 2, 2, 320)    0           ['batch_normalization_85[0][0]'] \n                                                                                                  \n mixed9_1 (Concatenate)         (None, 2, 2, 768)    0           ['activation_87[0][0]',          \n                                                                  'activation_88[0][0]']          \n                                                                                                  \n concatenate_1 (Concatenate)    (None, 2, 2, 768)    0           ['activation_91[0][0]',          \n                                                                  'activation_92[0][0]']          \n                                                                                                  \n activation_93 (Activation)     (None, 2, 2, 192)    0           ['batch_normalization_93[0][0]'] \n                                                                                                  \n mixed10 (Concatenate)          (None, 2, 2, 2048)   0           ['activation_85[0][0]',          \n                                                                  'mixed9_1[0][0]',               \n                                                                  'concatenate_1[0][0]',          \n                                                                  'activation_93[0][0]']          \n                                                                                                  \n flatten (Flatten)              (None, 8192)         0           ['mixed10[0][0]']                \n                                                                                                  \n dense (Dense)                  (None, 1)            8193        ['flatten[0][0]']                \n                                                                                                  \n==================================================================================================\nTotal params: 21,810,977\nTrainable params: 21,776,545\nNon-trainable params: 34,432\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"tf.random.set_seed(42)\nmodel.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T12:53:36.364442Z","iopub.execute_input":"2023-05-14T12:53:36.364954Z","iopub.status.idle":"2023-05-14T12:53:36.488347Z","shell.execute_reply.started":"2023-05-14T12:53:36.364909Z","shell.execute_reply":"2023-05-14T12:53:36.487408Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    train_data,\n    validation_data=val_data,\n    epochs=100,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=3,\n            restore_best_weights=True\n        )\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T12:53:36.489537Z","iopub.execute_input":"2023-05-14T12:53:36.489926Z","iopub.status.idle":"2023-05-14T13:09:10.606588Z","shell.execute_reply.started":"2023-05-14T12:53:36.489883Z","shell.execute_reply":"2023-05-14T13:09:10.605410Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Epoch 1/100\n800/800 [==============================] - 329s 348ms/step - loss: 0.0410 - accuracy: 0.9890 - val_loss: 0.0123 - val_accuracy: 0.9972\nEpoch 2/100\n800/800 [==============================] - 100s 125ms/step - loss: 0.0153 - accuracy: 0.9954 - val_loss: 0.0085 - val_accuracy: 0.9981\nEpoch 3/100\n800/800 [==============================] - 100s 125ms/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.0375 - val_accuracy: 0.9959\nEpoch 4/100\n800/800 [==============================] - 102s 127ms/step - loss: 0.0141 - accuracy: 0.9971 - val_loss: 0.0078 - val_accuracy: 0.9975\nEpoch 5/100\n800/800 [==============================] - 100s 125ms/step - loss: 0.0111 - accuracy: 0.9970 - val_loss: 0.0100 - val_accuracy: 0.9978\nEpoch 6/100\n800/800 [==============================] - 103s 128ms/step - loss: 0.0100 - accuracy: 0.9972 - val_loss: 0.0212 - val_accuracy: 0.9956\nEpoch 7/100\n800/800 [==============================] - 99s 124ms/step - loss: 0.0294 - accuracy: 0.9948 - val_loss: 0.2183 - val_accuracy: 0.9714\n","output_type":"stream"}]},{"cell_type":"code","source":"def evaluate_model(model, test_data):\n    \n    results = model.evaluate(test_data, verbose=0)\n    loss = results[0]\n    acc = results[1]\n    \n    print(\"    Test Loss: {:.5f}\".format(loss))\n    print(\"Test Accuracy: {:.2f}%\".format(acc * 100))\n    \n    y_pred = np.squeeze((model.predict(test_data) >= 0.5).astype(np.int))\n    cm = confusion_matrix(test_data.labels, y_pred)\n    clr = classification_report(test_data.labels, y_pred, target_names=[\"NEGATIVE\", \"POSITIVE\"],digits=4)\n    \n    plt.figure(figsize=(6, 6))\n    sns.heatmap(cm, annot=True, fmt='g', vmin=0, cmap='Blues', cbar=False)\n    plt.xticks(ticks=np.arange(2) + 0.5, labels=[\"NEGATIVE\", \"POSITIVE\"])\n    plt.yticks(ticks=np.arange(2) + 0.5, labels=[\"NEGATIVE\", \"POSITIVE\"])\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Actual\")\n    plt.title(\"Confusion Matrix\")\n    plt.show()\n    \n    print(\"Classification Report:\\n----------------------\\n\", clr)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T13:09:10.608574Z","iopub.execute_input":"2023-05-14T13:09:10.608963Z","iopub.status.idle":"2023-05-14T13:09:10.620878Z","shell.execute_reply.started":"2023-05-14T13:09:10.608918Z","shell.execute_reply":"2023-05-14T13:09:10.619640Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"evaluate_model(model, test_data)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T13:09:10.622725Z","iopub.execute_input":"2023-05-14T13:09:10.624525Z","iopub.status.idle":"2023-05-14T13:10:49.760350Z","shell.execute_reply.started":"2023-05-14T13:09:10.624472Z","shell.execute_reply":"2023-05-14T13:10:49.759220Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"    Test Loss: 0.00515\nTest Accuracy: 99.84%\n250/250 [==============================] - 24s 89ms/step\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  # Remove the CWD from sys.path while we load stuff.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 600x600 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"Classification Report:\n----------------------\n               precision    recall  f1-score   support\n\n    NEGATIVE     0.9987    0.9980    0.9984      3997\n    POSITIVE     0.9980    0.9988    0.9984      4003\n\n    accuracy                         0.9984      8000\n   macro avg     0.9984    0.9984    0.9984      8000\nweighted avg     0.9984    0.9984    0.9984      8000\n\n","output_type":"stream"}]},{"cell_type":"code","source":"model.predict(test_data)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T13:10:49.762238Z","iopub.execute_input":"2023-05-14T13:10:49.763022Z","iopub.status.idle":"2023-05-14T13:11:12.230668Z","shell.execute_reply.started":"2023-05-14T13:10:49.762966Z","shell.execute_reply":"2023-05-14T13:11:12.229237Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"250/250 [==============================] - 22s 89ms/step\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"array([[8.3396175e-05],\n       [9.9772602e-01],\n       [6.1424094e-04],\n       ...,\n       [9.9964833e-01],\n       [3.8339589e-05],\n       [1.9822559e-04]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"from PIL import Image\nimport numpy as np\nfrom skimage import transform\ndef load(filename):\n   np_image = Image.open(filename)\n   np_image = np.array(np_image).astype('float32')/255\n   np_image = transform.resize(np_image, (120, 120, 3))\n   np_image = np.expand_dims(np_image, axis=0)\n   return np_image\n\nimage = load('/kaggle/input/test-img2/images.jpeg')\npred = model.predict(image)\n\n\nif pred < 0.5:\n    print(\"No Crack\")\nelse:\n    print(\"Crack\")\n    ","metadata":{"execution":{"iopub.status.busy":"2023-05-14T13:11:12.232546Z","iopub.execute_input":"2023-05-14T13:11:12.233080Z","iopub.status.idle":"2023-05-14T13:11:14.608705Z","shell.execute_reply.started":"2023-05-14T13:11:12.233032Z","shell.execute_reply":"2023-05-14T13:11:14.607496Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 2s 2s/step\nCrack\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}