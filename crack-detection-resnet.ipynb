{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\nfrom pathlib import Path\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\n\nfrom sklearn.metrics import confusion_matrix, classification_report","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-14T11:10:19.501793Z","iopub.execute_input":"2023-05-14T11:10:19.502252Z","iopub.status.idle":"2023-05-14T11:10:40.121621Z","shell.execute_reply.started":"2023-05-14T11:10:19.502211Z","shell.execute_reply":"2023-05-14T11:10:40.120305Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"positive_dir = Path('../input/surface-crack-detection/Positive')\nnegative_dir = Path('../input/surface-crack-detection/Negative')","metadata":{"execution":{"iopub.status.busy":"2023-05-14T11:10:40.123996Z","iopub.execute_input":"2023-05-14T11:10:40.124992Z","iopub.status.idle":"2023-05-14T11:10:40.131723Z","shell.execute_reply.started":"2023-05-14T11:10:40.124954Z","shell.execute_reply":"2023-05-14T11:10:40.129175Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def generate_df(image_dir, label):\n    filepaths = pd.Series(list(image_dir.glob(r'*.jpg')), name='Filepath').astype(str)\n    labels = pd.Series(label, name='Label', index=filepaths.index)\n    df = pd.concat([filepaths, labels], axis=1)\n    return df","metadata":{"execution":{"iopub.status.busy":"2023-05-14T11:10:40.132871Z","iopub.execute_input":"2023-05-14T11:10:40.133252Z","iopub.status.idle":"2023-05-14T11:10:40.146953Z","shell.execute_reply.started":"2023-05-14T11:10:40.133214Z","shell.execute_reply":"2023-05-14T11:10:40.145860Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"positive_df = generate_df(positive_dir, label=\"POSITIVE\")\nnegative_df = generate_df(negative_dir, label=\"NEGATIVE\")\n\nall_df = pd.concat([positive_df, negative_df], axis=0).sample(frac=1.0, random_state=1).reset_index(drop=True)\nall_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-14T11:10:40.151557Z","iopub.execute_input":"2023-05-14T11:10:40.151969Z","iopub.status.idle":"2023-05-14T11:10:41.406061Z","shell.execute_reply.started":"2023-05-14T11:10:40.151940Z","shell.execute_reply":"2023-05-14T11:10:41.404909Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                            Filepath     Label\n0  ../input/surface-crack-detection/Positive/0574...  POSITIVE\n1  ../input/surface-crack-detection/Positive/1870...  POSITIVE\n2  ../input/surface-crack-detection/Positive/0967...  POSITIVE\n3  ../input/surface-crack-detection/Negative/0791...  NEGATIVE\n4  ../input/surface-crack-detection/Positive/1400...  POSITIVE","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Filepath</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>../input/surface-crack-detection/Positive/0574...</td>\n      <td>POSITIVE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>../input/surface-crack-detection/Positive/1870...</td>\n      <td>POSITIVE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>../input/surface-crack-detection/Positive/0967...</td>\n      <td>POSITIVE</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>../input/surface-crack-detection/Negative/0791...</td>\n      <td>NEGATIVE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>../input/surface-crack-detection/Positive/1400...</td>\n      <td>POSITIVE</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_df, test_df = train_test_split(\n    all_df,\n    train_size=0.8,\n    shuffle=True,\n    random_state=1\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T11:10:41.407469Z","iopub.execute_input":"2023-05-14T11:10:41.408017Z","iopub.status.idle":"2023-05-14T11:10:41.419168Z","shell.execute_reply.started":"2023-05-14T11:10:41.407898Z","shell.execute_reply":"2023-05-14T11:10:41.418067Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1./255,\n    validation_split=0.2\n)\n\ntest_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1./255\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T11:10:41.421140Z","iopub.execute_input":"2023-05-14T11:10:41.421595Z","iopub.status.idle":"2023-05-14T11:10:41.428160Z","shell.execute_reply.started":"2023-05-14T11:10:41.421548Z","shell.execute_reply":"2023-05-14T11:10:41.427018Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_data = train_gen.flow_from_dataframe(\n    train_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(120, 120),\n    color_mode='rgb',\n    class_mode='binary',\n    batch_size=32,\n    shuffle=True,\n    seed=42,\n    subset='training'\n)\n\nval_data = train_gen.flow_from_dataframe(\n    train_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(120, 120),\n    color_mode='rgb',\n    class_mode='binary',\n    batch_size=32,\n    shuffle=True,\n    seed=42,\n    subset='validation'\n)\n\ntest_data = train_gen.flow_from_dataframe(\n    test_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(120, 120),\n    color_mode='rgb',\n    class_mode='binary',\n    batch_size=32,\n    shuffle=False,\n    seed=42\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T11:10:41.429772Z","iopub.execute_input":"2023-05-14T11:10:41.430423Z","iopub.status.idle":"2023-05-14T11:12:41.103021Z","shell.execute_reply.started":"2023-05-14T11:10:41.430384Z","shell.execute_reply":"2023-05-14T11:12:41.101861Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Found 25600 validated image filenames belonging to 2 classes.\nFound 6400 validated image filenames belonging to 2 classes.\nFound 8000 validated image filenames belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.applications.resnet import ResNet101\n\nresNet = ResNet101(include_top = False,\n                       input_shape = (120,120,3),\n                       weights ='imagenet')","metadata":{"execution":{"iopub.status.busy":"2023-05-14T11:12:41.104576Z","iopub.execute_input":"2023-05-14T11:12:41.105301Z","iopub.status.idle":"2023-05-14T11:12:51.170929Z","shell.execute_reply.started":"2023-05-14T11:12:41.105263Z","shell.execute_reply":"2023-05-14T11:12:51.169303Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101_weights_tf_dim_ordering_tf_kernels_notop.h5\n171446536/171446536 [==============================] - 1s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"x = tf.keras.layers.Flatten()(resNet.output)\noutputs = tf.keras.layers.Dense(1,activation='sigmoid')(x)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T11:12:51.172895Z","iopub.execute_input":"2023-05-14T11:12:51.173286Z","iopub.status.idle":"2023-05-14T11:12:51.216022Z","shell.execute_reply.started":"2023-05-14T11:12:51.173244Z","shell.execute_reply":"2023-05-14T11:12:51.215016Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.Model(inputs = resNet.input,outputs=outputs)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-05-14T11:12:51.222965Z","iopub.execute_input":"2023-05-14T11:12:51.226938Z","iopub.status.idle":"2023-05-14T11:12:52.636076Z","shell.execute_reply.started":"2023-05-14T11:12:51.226898Z","shell.execute_reply":"2023-05-14T11:12:52.635221Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_1 (InputLayer)           [(None, 120, 120, 3  0           []                               \n                                )]                                                                \n                                                                                                  \n conv1_pad (ZeroPadding2D)      (None, 126, 126, 3)  0           ['input_1[0][0]']                \n                                                                                                  \n conv1_conv (Conv2D)            (None, 60, 60, 64)   9472        ['conv1_pad[0][0]']              \n                                                                                                  \n conv1_bn (BatchNormalization)  (None, 60, 60, 64)   256         ['conv1_conv[0][0]']             \n                                                                                                  \n conv1_relu (Activation)        (None, 60, 60, 64)   0           ['conv1_bn[0][0]']               \n                                                                                                  \n pool1_pad (ZeroPadding2D)      (None, 62, 62, 64)   0           ['conv1_relu[0][0]']             \n                                                                                                  \n pool1_pool (MaxPooling2D)      (None, 30, 30, 64)   0           ['pool1_pad[0][0]']              \n                                                                                                  \n conv2_block1_1_conv (Conv2D)   (None, 30, 30, 64)   4160        ['pool1_pool[0][0]']             \n                                                                                                  \n conv2_block1_1_bn (BatchNormal  (None, 30, 30, 64)  256         ['conv2_block1_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv2_block1_1_relu (Activatio  (None, 30, 30, 64)  0           ['conv2_block1_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv2_block1_2_conv (Conv2D)   (None, 30, 30, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n                                                                                                  \n conv2_block1_2_bn (BatchNormal  (None, 30, 30, 64)  256         ['conv2_block1_2_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv2_block1_2_relu (Activatio  (None, 30, 30, 64)  0           ['conv2_block1_2_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv2_block1_0_conv (Conv2D)   (None, 30, 30, 256)  16640       ['pool1_pool[0][0]']             \n                                                                                                  \n conv2_block1_3_conv (Conv2D)   (None, 30, 30, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n                                                                                                  \n conv2_block1_0_bn (BatchNormal  (None, 30, 30, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv2_block1_3_bn (BatchNormal  (None, 30, 30, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv2_block1_add (Add)         (None, 30, 30, 256)  0           ['conv2_block1_0_bn[0][0]',      \n                                                                  'conv2_block1_3_bn[0][0]']      \n                                                                                                  \n conv2_block1_out (Activation)  (None, 30, 30, 256)  0           ['conv2_block1_add[0][0]']       \n                                                                                                  \n conv2_block2_1_conv (Conv2D)   (None, 30, 30, 64)   16448       ['conv2_block1_out[0][0]']       \n                                                                                                  \n conv2_block2_1_bn (BatchNormal  (None, 30, 30, 64)  256         ['conv2_block2_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv2_block2_1_relu (Activatio  (None, 30, 30, 64)  0           ['conv2_block2_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv2_block2_2_conv (Conv2D)   (None, 30, 30, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n                                                                                                  \n conv2_block2_2_bn (BatchNormal  (None, 30, 30, 64)  256         ['conv2_block2_2_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv2_block2_2_relu (Activatio  (None, 30, 30, 64)  0           ['conv2_block2_2_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv2_block2_3_conv (Conv2D)   (None, 30, 30, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n                                                                                                  \n conv2_block2_3_bn (BatchNormal  (None, 30, 30, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv2_block2_add (Add)         (None, 30, 30, 256)  0           ['conv2_block1_out[0][0]',       \n                                                                  'conv2_block2_3_bn[0][0]']      \n                                                                                                  \n conv2_block2_out (Activation)  (None, 30, 30, 256)  0           ['conv2_block2_add[0][0]']       \n                                                                                                  \n conv2_block3_1_conv (Conv2D)   (None, 30, 30, 64)   16448       ['conv2_block2_out[0][0]']       \n                                                                                                  \n conv2_block3_1_bn (BatchNormal  (None, 30, 30, 64)  256         ['conv2_block3_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv2_block3_1_relu (Activatio  (None, 30, 30, 64)  0           ['conv2_block3_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv2_block3_2_conv (Conv2D)   (None, 30, 30, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n                                                                                                  \n conv2_block3_2_bn (BatchNormal  (None, 30, 30, 64)  256         ['conv2_block3_2_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv2_block3_2_relu (Activatio  (None, 30, 30, 64)  0           ['conv2_block3_2_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv2_block3_3_conv (Conv2D)   (None, 30, 30, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n                                                                                                  \n conv2_block3_3_bn (BatchNormal  (None, 30, 30, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv2_block3_add (Add)         (None, 30, 30, 256)  0           ['conv2_block2_out[0][0]',       \n                                                                  'conv2_block3_3_bn[0][0]']      \n                                                                                                  \n conv2_block3_out (Activation)  (None, 30, 30, 256)  0           ['conv2_block3_add[0][0]']       \n                                                                                                  \n conv3_block1_1_conv (Conv2D)   (None, 15, 15, 128)  32896       ['conv2_block3_out[0][0]']       \n                                                                                                  \n conv3_block1_1_bn (BatchNormal  (None, 15, 15, 128)  512        ['conv3_block1_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block1_1_relu (Activatio  (None, 15, 15, 128)  0          ['conv3_block1_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block1_2_conv (Conv2D)   (None, 15, 15, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n                                                                                                  \n conv3_block1_2_bn (BatchNormal  (None, 15, 15, 128)  512        ['conv3_block1_2_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block1_2_relu (Activatio  (None, 15, 15, 128)  0          ['conv3_block1_2_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block1_0_conv (Conv2D)   (None, 15, 15, 512)  131584      ['conv2_block3_out[0][0]']       \n                                                                                                  \n conv3_block1_3_conv (Conv2D)   (None, 15, 15, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n                                                                                                  \n conv3_block1_0_bn (BatchNormal  (None, 15, 15, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block1_3_bn (BatchNormal  (None, 15, 15, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block1_add (Add)         (None, 15, 15, 512)  0           ['conv3_block1_0_bn[0][0]',      \n                                                                  'conv3_block1_3_bn[0][0]']      \n                                                                                                  \n conv3_block1_out (Activation)  (None, 15, 15, 512)  0           ['conv3_block1_add[0][0]']       \n                                                                                                  \n conv3_block2_1_conv (Conv2D)   (None, 15, 15, 128)  65664       ['conv3_block1_out[0][0]']       \n                                                                                                  \n conv3_block2_1_bn (BatchNormal  (None, 15, 15, 128)  512        ['conv3_block2_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block2_1_relu (Activatio  (None, 15, 15, 128)  0          ['conv3_block2_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block2_2_conv (Conv2D)   (None, 15, 15, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n                                                                                                  \n conv3_block2_2_bn (BatchNormal  (None, 15, 15, 128)  512        ['conv3_block2_2_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block2_2_relu (Activatio  (None, 15, 15, 128)  0          ['conv3_block2_2_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block2_3_conv (Conv2D)   (None, 15, 15, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n                                                                                                  \n conv3_block2_3_bn (BatchNormal  (None, 15, 15, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block2_add (Add)         (None, 15, 15, 512)  0           ['conv3_block1_out[0][0]',       \n                                                                  'conv3_block2_3_bn[0][0]']      \n                                                                                                  \n conv3_block2_out (Activation)  (None, 15, 15, 512)  0           ['conv3_block2_add[0][0]']       \n                                                                                                  \n conv3_block3_1_conv (Conv2D)   (None, 15, 15, 128)  65664       ['conv3_block2_out[0][0]']       \n                                                                                                  \n conv3_block3_1_bn (BatchNormal  (None, 15, 15, 128)  512        ['conv3_block3_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block3_1_relu (Activatio  (None, 15, 15, 128)  0          ['conv3_block3_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block3_2_conv (Conv2D)   (None, 15, 15, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n                                                                                                  \n conv3_block3_2_bn (BatchNormal  (None, 15, 15, 128)  512        ['conv3_block3_2_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block3_2_relu (Activatio  (None, 15, 15, 128)  0          ['conv3_block3_2_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block3_3_conv (Conv2D)   (None, 15, 15, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n                                                                                                  \n conv3_block3_3_bn (BatchNormal  (None, 15, 15, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block3_add (Add)         (None, 15, 15, 512)  0           ['conv3_block2_out[0][0]',       \n                                                                  'conv3_block3_3_bn[0][0]']      \n                                                                                                  \n conv3_block3_out (Activation)  (None, 15, 15, 512)  0           ['conv3_block3_add[0][0]']       \n                                                                                                  \n conv3_block4_1_conv (Conv2D)   (None, 15, 15, 128)  65664       ['conv3_block3_out[0][0]']       \n                                                                                                  \n conv3_block4_1_bn (BatchNormal  (None, 15, 15, 128)  512        ['conv3_block4_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block4_1_relu (Activatio  (None, 15, 15, 128)  0          ['conv3_block4_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block4_2_conv (Conv2D)   (None, 15, 15, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n                                                                                                  \n conv3_block4_2_bn (BatchNormal  (None, 15, 15, 128)  512        ['conv3_block4_2_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block4_2_relu (Activatio  (None, 15, 15, 128)  0          ['conv3_block4_2_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block4_3_conv (Conv2D)   (None, 15, 15, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n                                                                                                  \n conv3_block4_3_bn (BatchNormal  (None, 15, 15, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block4_add (Add)         (None, 15, 15, 512)  0           ['conv3_block3_out[0][0]',       \n                                                                  'conv3_block4_3_bn[0][0]']      \n                                                                                                  \n conv3_block4_out (Activation)  (None, 15, 15, 512)  0           ['conv3_block4_add[0][0]']       \n                                                                                                  \n conv4_block1_1_conv (Conv2D)   (None, 8, 8, 256)    131328      ['conv3_block4_out[0][0]']       \n                                                                                                  \n conv4_block1_1_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block1_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block1_1_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block1_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block1_2_conv (Conv2D)   (None, 8, 8, 256)    590080      ['conv4_block1_1_relu[0][0]']    \n                                                                                                  \n conv4_block1_2_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block1_2_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block1_2_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block1_2_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block1_0_conv (Conv2D)   (None, 8, 8, 1024)   525312      ['conv3_block4_out[0][0]']       \n                                                                                                  \n conv4_block1_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      ['conv4_block1_2_relu[0][0]']    \n                                                                                                  \n conv4_block1_0_bn (BatchNormal  (None, 8, 8, 1024)  4096        ['conv4_block1_0_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block1_3_bn (BatchNormal  (None, 8, 8, 1024)  4096        ['conv4_block1_3_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block1_add (Add)         (None, 8, 8, 1024)   0           ['conv4_block1_0_bn[0][0]',      \n                                                                  'conv4_block1_3_bn[0][0]']      \n                                                                                                  \n conv4_block1_out (Activation)  (None, 8, 8, 1024)   0           ['conv4_block1_add[0][0]']       \n                                                                                                  \n conv4_block2_1_conv (Conv2D)   (None, 8, 8, 256)    262400      ['conv4_block1_out[0][0]']       \n                                                                                                  \n conv4_block2_1_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block2_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block2_1_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block2_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block2_2_conv (Conv2D)   (None, 8, 8, 256)    590080      ['conv4_block2_1_relu[0][0]']    \n                                                                                                  \n conv4_block2_2_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block2_2_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block2_2_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block2_2_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block2_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      ['conv4_block2_2_relu[0][0]']    \n                                                                                                  \n conv4_block2_3_bn (BatchNormal  (None, 8, 8, 1024)  4096        ['conv4_block2_3_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block2_add (Add)         (None, 8, 8, 1024)   0           ['conv4_block1_out[0][0]',       \n                                                                  'conv4_block2_3_bn[0][0]']      \n                                                                                                  \n conv4_block2_out (Activation)  (None, 8, 8, 1024)   0           ['conv4_block2_add[0][0]']       \n                                                                                                  \n conv4_block3_1_conv (Conv2D)   (None, 8, 8, 256)    262400      ['conv4_block2_out[0][0]']       \n                                                                                                  \n conv4_block3_1_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block3_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block3_1_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block3_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block3_2_conv (Conv2D)   (None, 8, 8, 256)    590080      ['conv4_block3_1_relu[0][0]']    \n                                                                                                  \n conv4_block3_2_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block3_2_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block3_2_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block3_2_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block3_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      ['conv4_block3_2_relu[0][0]']    \n                                                                                                  \n conv4_block3_3_bn (BatchNormal  (None, 8, 8, 1024)  4096        ['conv4_block3_3_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block3_add (Add)         (None, 8, 8, 1024)   0           ['conv4_block2_out[0][0]',       \n                                                                  'conv4_block3_3_bn[0][0]']      \n                                                                                                  \n conv4_block3_out (Activation)  (None, 8, 8, 1024)   0           ['conv4_block3_add[0][0]']       \n                                                                                                  \n conv4_block4_1_conv (Conv2D)   (None, 8, 8, 256)    262400      ['conv4_block3_out[0][0]']       \n                                                                                                  \n conv4_block4_1_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block4_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block4_1_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block4_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block4_2_conv (Conv2D)   (None, 8, 8, 256)    590080      ['conv4_block4_1_relu[0][0]']    \n                                                                                                  \n conv4_block4_2_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block4_2_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block4_2_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block4_2_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block4_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      ['conv4_block4_2_relu[0][0]']    \n                                                                                                  \n conv4_block4_3_bn (BatchNormal  (None, 8, 8, 1024)  4096        ['conv4_block4_3_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block4_add (Add)         (None, 8, 8, 1024)   0           ['conv4_block3_out[0][0]',       \n                                                                  'conv4_block4_3_bn[0][0]']      \n                                                                                                  \n conv4_block4_out (Activation)  (None, 8, 8, 1024)   0           ['conv4_block4_add[0][0]']       \n                                                                                                  \n conv4_block5_1_conv (Conv2D)   (None, 8, 8, 256)    262400      ['conv4_block4_out[0][0]']       \n                                                                                                  \n conv4_block5_1_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block5_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block5_1_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block5_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block5_2_conv (Conv2D)   (None, 8, 8, 256)    590080      ['conv4_block5_1_relu[0][0]']    \n                                                                                                  \n conv4_block5_2_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block5_2_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block5_2_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block5_2_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block5_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      ['conv4_block5_2_relu[0][0]']    \n                                                                                                  \n conv4_block5_3_bn (BatchNormal  (None, 8, 8, 1024)  4096        ['conv4_block5_3_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block5_add (Add)         (None, 8, 8, 1024)   0           ['conv4_block4_out[0][0]',       \n                                                                  'conv4_block5_3_bn[0][0]']      \n                                                                                                  \n conv4_block5_out (Activation)  (None, 8, 8, 1024)   0           ['conv4_block5_add[0][0]']       \n                                                                                                  \n conv4_block6_1_conv (Conv2D)   (None, 8, 8, 256)    262400      ['conv4_block5_out[0][0]']       \n                                                                                                  \n conv4_block6_1_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block6_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block6_1_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block6_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block6_2_conv (Conv2D)   (None, 8, 8, 256)    590080      ['conv4_block6_1_relu[0][0]']    \n                                                                                                  \n conv4_block6_2_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block6_2_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block6_2_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block6_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n                                                                                                  \n conv4_block6_3_bn (BatchNormal  (None, 8, 8, 1024)  4096        ['conv4_block6_3_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block6_add (Add)         (None, 8, 8, 1024)   0           ['conv4_block5_out[0][0]',       \n                                                                  'conv4_block6_3_bn[0][0]']      \n                                                                                                  \n conv4_block6_out (Activation)  (None, 8, 8, 1024)   0           ['conv4_block6_add[0][0]']       \n                                                                                                  \n conv4_block7_1_conv (Conv2D)   (None, 8, 8, 256)    262400      ['conv4_block6_out[0][0]']       \n                                                                                                  \n conv4_block7_1_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block7_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block7_1_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block7_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block7_2_conv (Conv2D)   (None, 8, 8, 256)    590080      ['conv4_block7_1_relu[0][0]']    \n                                                                                                  \n conv4_block7_2_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block7_2_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block7_2_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block7_2_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block7_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      ['conv4_block7_2_relu[0][0]']    \n                                                                                                  \n conv4_block7_3_bn (BatchNormal  (None, 8, 8, 1024)  4096        ['conv4_block7_3_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block7_add (Add)         (None, 8, 8, 1024)   0           ['conv4_block6_out[0][0]',       \n                                                                  'conv4_block7_3_bn[0][0]']      \n                                                                                                  \n conv4_block7_out (Activation)  (None, 8, 8, 1024)   0           ['conv4_block7_add[0][0]']       \n                                                                                                  \n conv4_block8_1_conv (Conv2D)   (None, 8, 8, 256)    262400      ['conv4_block7_out[0][0]']       \n                                                                                                  \n conv4_block8_1_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block8_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block8_1_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block8_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block8_2_conv (Conv2D)   (None, 8, 8, 256)    590080      ['conv4_block8_1_relu[0][0]']    \n                                                                                                  \n conv4_block8_2_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block8_2_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block8_2_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block8_2_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block8_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      ['conv4_block8_2_relu[0][0]']    \n                                                                                                  \n conv4_block8_3_bn (BatchNormal  (None, 8, 8, 1024)  4096        ['conv4_block8_3_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block8_add (Add)         (None, 8, 8, 1024)   0           ['conv4_block7_out[0][0]',       \n                                                                  'conv4_block8_3_bn[0][0]']      \n                                                                                                  \n conv4_block8_out (Activation)  (None, 8, 8, 1024)   0           ['conv4_block8_add[0][0]']       \n                                                                                                  \n conv4_block9_1_conv (Conv2D)   (None, 8, 8, 256)    262400      ['conv4_block8_out[0][0]']       \n                                                                                                  \n conv4_block9_1_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block9_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block9_1_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block9_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block9_2_conv (Conv2D)   (None, 8, 8, 256)    590080      ['conv4_block9_1_relu[0][0]']    \n                                                                                                  \n conv4_block9_2_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block9_2_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block9_2_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block9_2_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block9_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      ['conv4_block9_2_relu[0][0]']    \n                                                                                                  \n conv4_block9_3_bn (BatchNormal  (None, 8, 8, 1024)  4096        ['conv4_block9_3_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block9_add (Add)         (None, 8, 8, 1024)   0           ['conv4_block8_out[0][0]',       \n                                                                  'conv4_block9_3_bn[0][0]']      \n                                                                                                  \n conv4_block9_out (Activation)  (None, 8, 8, 1024)   0           ['conv4_block9_add[0][0]']       \n                                                                                                  \n conv4_block10_1_conv (Conv2D)  (None, 8, 8, 256)    262400      ['conv4_block9_out[0][0]']       \n                                                                                                  \n conv4_block10_1_bn (BatchNorma  (None, 8, 8, 256)   1024        ['conv4_block10_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block10_1_relu (Activati  (None, 8, 8, 256)   0           ['conv4_block10_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block10_2_conv (Conv2D)  (None, 8, 8, 256)    590080      ['conv4_block10_1_relu[0][0]']   \n                                                                                                  \n conv4_block10_2_bn (BatchNorma  (None, 8, 8, 256)   1024        ['conv4_block10_2_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block10_2_relu (Activati  (None, 8, 8, 256)   0           ['conv4_block10_2_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block10_3_conv (Conv2D)  (None, 8, 8, 1024)   263168      ['conv4_block10_2_relu[0][0]']   \n                                                                                                  \n conv4_block10_3_bn (BatchNorma  (None, 8, 8, 1024)  4096        ['conv4_block10_3_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block10_add (Add)        (None, 8, 8, 1024)   0           ['conv4_block9_out[0][0]',       \n                                                                  'conv4_block10_3_bn[0][0]']     \n                                                                                                  \n conv4_block10_out (Activation)  (None, 8, 8, 1024)  0           ['conv4_block10_add[0][0]']      \n                                                                                                  \n conv4_block11_1_conv (Conv2D)  (None, 8, 8, 256)    262400      ['conv4_block10_out[0][0]']      \n                                                                                                  \n conv4_block11_1_bn (BatchNorma  (None, 8, 8, 256)   1024        ['conv4_block11_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block11_1_relu (Activati  (None, 8, 8, 256)   0           ['conv4_block11_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block11_2_conv (Conv2D)  (None, 8, 8, 256)    590080      ['conv4_block11_1_relu[0][0]']   \n                                                                                                  \n conv4_block11_2_bn (BatchNorma  (None, 8, 8, 256)   1024        ['conv4_block11_2_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block11_2_relu (Activati  (None, 8, 8, 256)   0           ['conv4_block11_2_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block11_3_conv (Conv2D)  (None, 8, 8, 1024)   263168      ['conv4_block11_2_relu[0][0]']   \n                                                                                                  \n conv4_block11_3_bn (BatchNorma  (None, 8, 8, 1024)  4096        ['conv4_block11_3_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block11_add (Add)        (None, 8, 8, 1024)   0           ['conv4_block10_out[0][0]',      \n                                                                  'conv4_block11_3_bn[0][0]']     \n                                                                                                  \n conv4_block11_out (Activation)  (None, 8, 8, 1024)  0           ['conv4_block11_add[0][0]']      \n                                                                                                  \n conv4_block12_1_conv (Conv2D)  (None, 8, 8, 256)    262400      ['conv4_block11_out[0][0]']      \n                                                                                                  \n conv4_block12_1_bn (BatchNorma  (None, 8, 8, 256)   1024        ['conv4_block12_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block12_1_relu (Activati  (None, 8, 8, 256)   0           ['conv4_block12_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block12_2_conv (Conv2D)  (None, 8, 8, 256)    590080      ['conv4_block12_1_relu[0][0]']   \n                                                                                                  \n conv4_block12_2_bn (BatchNorma  (None, 8, 8, 256)   1024        ['conv4_block12_2_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block12_2_relu (Activati  (None, 8, 8, 256)   0           ['conv4_block12_2_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block12_3_conv (Conv2D)  (None, 8, 8, 1024)   263168      ['conv4_block12_2_relu[0][0]']   \n                                                                                                  \n conv4_block12_3_bn (BatchNorma  (None, 8, 8, 1024)  4096        ['conv4_block12_3_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block12_add (Add)        (None, 8, 8, 1024)   0           ['conv4_block11_out[0][0]',      \n                                                                  'conv4_block12_3_bn[0][0]']     \n                                                                                                  \n conv4_block12_out (Activation)  (None, 8, 8, 1024)  0           ['conv4_block12_add[0][0]']      \n                                                                                                  \n conv4_block13_1_conv (Conv2D)  (None, 8, 8, 256)    262400      ['conv4_block12_out[0][0]']      \n                                                                                                  \n conv4_block13_1_bn (BatchNorma  (None, 8, 8, 256)   1024        ['conv4_block13_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block13_1_relu (Activati  (None, 8, 8, 256)   0           ['conv4_block13_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block13_2_conv (Conv2D)  (None, 8, 8, 256)    590080      ['conv4_block13_1_relu[0][0]']   \n                                                                                                  \n conv4_block13_2_bn (BatchNorma  (None, 8, 8, 256)   1024        ['conv4_block13_2_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block13_2_relu (Activati  (None, 8, 8, 256)   0           ['conv4_block13_2_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block13_3_conv (Conv2D)  (None, 8, 8, 1024)   263168      ['conv4_block13_2_relu[0][0]']   \n                                                                                                  \n conv4_block13_3_bn (BatchNorma  (None, 8, 8, 1024)  4096        ['conv4_block13_3_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block13_add (Add)        (None, 8, 8, 1024)   0           ['conv4_block12_out[0][0]',      \n                                                                  'conv4_block13_3_bn[0][0]']     \n                                                                                                  \n conv4_block13_out (Activation)  (None, 8, 8, 1024)  0           ['conv4_block13_add[0][0]']      \n                                                                                                  \n conv4_block14_1_conv (Conv2D)  (None, 8, 8, 256)    262400      ['conv4_block13_out[0][0]']      \n                                                                                                  \n conv4_block14_1_bn (BatchNorma  (None, 8, 8, 256)   1024        ['conv4_block14_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block14_1_relu (Activati  (None, 8, 8, 256)   0           ['conv4_block14_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block14_2_conv (Conv2D)  (None, 8, 8, 256)    590080      ['conv4_block14_1_relu[0][0]']   \n                                                                                                  \n conv4_block14_2_bn (BatchNorma  (None, 8, 8, 256)   1024        ['conv4_block14_2_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block14_2_relu (Activati  (None, 8, 8, 256)   0           ['conv4_block14_2_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block14_3_conv (Conv2D)  (None, 8, 8, 1024)   263168      ['conv4_block14_2_relu[0][0]']   \n                                                                                                  \n conv4_block14_3_bn (BatchNorma  (None, 8, 8, 1024)  4096        ['conv4_block14_3_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block14_add (Add)        (None, 8, 8, 1024)   0           ['conv4_block13_out[0][0]',      \n                                                                  'conv4_block14_3_bn[0][0]']     \n                                                                                                  \n conv4_block14_out (Activation)  (None, 8, 8, 1024)  0           ['conv4_block14_add[0][0]']      \n                                                                                                  \n conv4_block15_1_conv (Conv2D)  (None, 8, 8, 256)    262400      ['conv4_block14_out[0][0]']      \n                                                                                                  \n conv4_block15_1_bn (BatchNorma  (None, 8, 8, 256)   1024        ['conv4_block15_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block15_1_relu (Activati  (None, 8, 8, 256)   0           ['conv4_block15_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block15_2_conv (Conv2D)  (None, 8, 8, 256)    590080      ['conv4_block15_1_relu[0][0]']   \n                                                                                                  \n conv4_block15_2_bn (BatchNorma  (None, 8, 8, 256)   1024        ['conv4_block15_2_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block15_2_relu (Activati  (None, 8, 8, 256)   0           ['conv4_block15_2_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block15_3_conv (Conv2D)  (None, 8, 8, 1024)   263168      ['conv4_block15_2_relu[0][0]']   \n                                                                                                  \n conv4_block15_3_bn (BatchNorma  (None, 8, 8, 1024)  4096        ['conv4_block15_3_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block15_add (Add)        (None, 8, 8, 1024)   0           ['conv4_block14_out[0][0]',      \n                                                                  'conv4_block15_3_bn[0][0]']     \n                                                                                                  \n conv4_block15_out (Activation)  (None, 8, 8, 1024)  0           ['conv4_block15_add[0][0]']      \n                                                                                                  \n conv4_block16_1_conv (Conv2D)  (None, 8, 8, 256)    262400      ['conv4_block15_out[0][0]']      \n                                                                                                  \n conv4_block16_1_bn (BatchNorma  (None, 8, 8, 256)   1024        ['conv4_block16_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block16_1_relu (Activati  (None, 8, 8, 256)   0           ['conv4_block16_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block16_2_conv (Conv2D)  (None, 8, 8, 256)    590080      ['conv4_block16_1_relu[0][0]']   \n                                                                                                  \n conv4_block16_2_bn (BatchNorma  (None, 8, 8, 256)   1024        ['conv4_block16_2_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block16_2_relu (Activati  (None, 8, 8, 256)   0           ['conv4_block16_2_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block16_3_conv (Conv2D)  (None, 8, 8, 1024)   263168      ['conv4_block16_2_relu[0][0]']   \n                                                                                                  \n conv4_block16_3_bn (BatchNorma  (None, 8, 8, 1024)  4096        ['conv4_block16_3_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block16_add (Add)        (None, 8, 8, 1024)   0           ['conv4_block15_out[0][0]',      \n                                                                  'conv4_block16_3_bn[0][0]']     \n                                                                                                  \n conv4_block16_out (Activation)  (None, 8, 8, 1024)  0           ['conv4_block16_add[0][0]']      \n                                                                                                  \n conv4_block17_1_conv (Conv2D)  (None, 8, 8, 256)    262400      ['conv4_block16_out[0][0]']      \n                                                                                                  \n conv4_block17_1_bn (BatchNorma  (None, 8, 8, 256)   1024        ['conv4_block17_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block17_1_relu (Activati  (None, 8, 8, 256)   0           ['conv4_block17_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block17_2_conv (Conv2D)  (None, 8, 8, 256)    590080      ['conv4_block17_1_relu[0][0]']   \n                                                                                                  \n conv4_block17_2_bn (BatchNorma  (None, 8, 8, 256)   1024        ['conv4_block17_2_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block17_2_relu (Activati  (None, 8, 8, 256)   0           ['conv4_block17_2_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block17_3_conv (Conv2D)  (None, 8, 8, 1024)   263168      ['conv4_block17_2_relu[0][0]']   \n                                                                                                  \n conv4_block17_3_bn (BatchNorma  (None, 8, 8, 1024)  4096        ['conv4_block17_3_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block17_add (Add)        (None, 8, 8, 1024)   0           ['conv4_block16_out[0][0]',      \n                                                                  'conv4_block17_3_bn[0][0]']     \n                                                                                                  \n conv4_block17_out (Activation)  (None, 8, 8, 1024)  0           ['conv4_block17_add[0][0]']      \n                                                                                                  \n conv4_block18_1_conv (Conv2D)  (None, 8, 8, 256)    262400      ['conv4_block17_out[0][0]']      \n                                                                                                  \n conv4_block18_1_bn (BatchNorma  (None, 8, 8, 256)   1024        ['conv4_block18_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block18_1_relu (Activati  (None, 8, 8, 256)   0           ['conv4_block18_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block18_2_conv (Conv2D)  (None, 8, 8, 256)    590080      ['conv4_block18_1_relu[0][0]']   \n                                                                                                  \n conv4_block18_2_bn (BatchNorma  (None, 8, 8, 256)   1024        ['conv4_block18_2_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block18_2_relu (Activati  (None, 8, 8, 256)   0           ['conv4_block18_2_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block18_3_conv (Conv2D)  (None, 8, 8, 1024)   263168      ['conv4_block18_2_relu[0][0]']   \n                                                                                                  \n conv4_block18_3_bn (BatchNorma  (None, 8, 8, 1024)  4096        ['conv4_block18_3_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block18_add (Add)        (None, 8, 8, 1024)   0           ['conv4_block17_out[0][0]',      \n                                                                  'conv4_block18_3_bn[0][0]']     \n                                                                                                  \n conv4_block18_out (Activation)  (None, 8, 8, 1024)  0           ['conv4_block18_add[0][0]']      \n                                                                                                  \n conv4_block19_1_conv (Conv2D)  (None, 8, 8, 256)    262400      ['conv4_block18_out[0][0]']      \n                                                                                                  \n conv4_block19_1_bn (BatchNorma  (None, 8, 8, 256)   1024        ['conv4_block19_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block19_1_relu (Activati  (None, 8, 8, 256)   0           ['conv4_block19_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block19_2_conv (Conv2D)  (None, 8, 8, 256)    590080      ['conv4_block19_1_relu[0][0]']   \n                                                                                                  \n conv4_block19_2_bn (BatchNorma  (None, 8, 8, 256)   1024        ['conv4_block19_2_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block19_2_relu (Activati  (None, 8, 8, 256)   0           ['conv4_block19_2_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block19_3_conv (Conv2D)  (None, 8, 8, 1024)   263168      ['conv4_block19_2_relu[0][0]']   \n                                                                                                  \n conv4_block19_3_bn (BatchNorma  (None, 8, 8, 1024)  4096        ['conv4_block19_3_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block19_add (Add)        (None, 8, 8, 1024)   0           ['conv4_block18_out[0][0]',      \n                                                                  'conv4_block19_3_bn[0][0]']     \n                                                                                                  \n conv4_block19_out (Activation)  (None, 8, 8, 1024)  0           ['conv4_block19_add[0][0]']      \n                                                                                                  \n conv4_block20_1_conv (Conv2D)  (None, 8, 8, 256)    262400      ['conv4_block19_out[0][0]']      \n                                                                                                  \n conv4_block20_1_bn (BatchNorma  (None, 8, 8, 256)   1024        ['conv4_block20_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block20_1_relu (Activati  (None, 8, 8, 256)   0           ['conv4_block20_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block20_2_conv (Conv2D)  (None, 8, 8, 256)    590080      ['conv4_block20_1_relu[0][0]']   \n                                                                                                  \n conv4_block20_2_bn (BatchNorma  (None, 8, 8, 256)   1024        ['conv4_block20_2_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block20_2_relu (Activati  (None, 8, 8, 256)   0           ['conv4_block20_2_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block20_3_conv (Conv2D)  (None, 8, 8, 1024)   263168      ['conv4_block20_2_relu[0][0]']   \n                                                                                                  \n conv4_block20_3_bn (BatchNorma  (None, 8, 8, 1024)  4096        ['conv4_block20_3_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block20_add (Add)        (None, 8, 8, 1024)   0           ['conv4_block19_out[0][0]',      \n                                                                  'conv4_block20_3_bn[0][0]']     \n                                                                                                  \n conv4_block20_out (Activation)  (None, 8, 8, 1024)  0           ['conv4_block20_add[0][0]']      \n                                                                                                  \n conv4_block21_1_conv (Conv2D)  (None, 8, 8, 256)    262400      ['conv4_block20_out[0][0]']      \n                                                                                                  \n conv4_block21_1_bn (BatchNorma  (None, 8, 8, 256)   1024        ['conv4_block21_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block21_1_relu (Activati  (None, 8, 8, 256)   0           ['conv4_block21_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block21_2_conv (Conv2D)  (None, 8, 8, 256)    590080      ['conv4_block21_1_relu[0][0]']   \n                                                                                                  \n conv4_block21_2_bn (BatchNorma  (None, 8, 8, 256)   1024        ['conv4_block21_2_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block21_2_relu (Activati  (None, 8, 8, 256)   0           ['conv4_block21_2_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block21_3_conv (Conv2D)  (None, 8, 8, 1024)   263168      ['conv4_block21_2_relu[0][0]']   \n                                                                                                  \n conv4_block21_3_bn (BatchNorma  (None, 8, 8, 1024)  4096        ['conv4_block21_3_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block21_add (Add)        (None, 8, 8, 1024)   0           ['conv4_block20_out[0][0]',      \n                                                                  'conv4_block21_3_bn[0][0]']     \n                                                                                                  \n conv4_block21_out (Activation)  (None, 8, 8, 1024)  0           ['conv4_block21_add[0][0]']      \n                                                                                                  \n conv4_block22_1_conv (Conv2D)  (None, 8, 8, 256)    262400      ['conv4_block21_out[0][0]']      \n                                                                                                  \n conv4_block22_1_bn (BatchNorma  (None, 8, 8, 256)   1024        ['conv4_block22_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block22_1_relu (Activati  (None, 8, 8, 256)   0           ['conv4_block22_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block22_2_conv (Conv2D)  (None, 8, 8, 256)    590080      ['conv4_block22_1_relu[0][0]']   \n                                                                                                  \n conv4_block22_2_bn (BatchNorma  (None, 8, 8, 256)   1024        ['conv4_block22_2_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block22_2_relu (Activati  (None, 8, 8, 256)   0           ['conv4_block22_2_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block22_3_conv (Conv2D)  (None, 8, 8, 1024)   263168      ['conv4_block22_2_relu[0][0]']   \n                                                                                                  \n conv4_block22_3_bn (BatchNorma  (None, 8, 8, 1024)  4096        ['conv4_block22_3_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block22_add (Add)        (None, 8, 8, 1024)   0           ['conv4_block21_out[0][0]',      \n                                                                  'conv4_block22_3_bn[0][0]']     \n                                                                                                  \n conv4_block22_out (Activation)  (None, 8, 8, 1024)  0           ['conv4_block22_add[0][0]']      \n                                                                                                  \n conv4_block23_1_conv (Conv2D)  (None, 8, 8, 256)    262400      ['conv4_block22_out[0][0]']      \n                                                                                                  \n conv4_block23_1_bn (BatchNorma  (None, 8, 8, 256)   1024        ['conv4_block23_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block23_1_relu (Activati  (None, 8, 8, 256)   0           ['conv4_block23_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block23_2_conv (Conv2D)  (None, 8, 8, 256)    590080      ['conv4_block23_1_relu[0][0]']   \n                                                                                                  \n conv4_block23_2_bn (BatchNorma  (None, 8, 8, 256)   1024        ['conv4_block23_2_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block23_2_relu (Activati  (None, 8, 8, 256)   0           ['conv4_block23_2_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block23_3_conv (Conv2D)  (None, 8, 8, 1024)   263168      ['conv4_block23_2_relu[0][0]']   \n                                                                                                  \n conv4_block23_3_bn (BatchNorma  (None, 8, 8, 1024)  4096        ['conv4_block23_3_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block23_add (Add)        (None, 8, 8, 1024)   0           ['conv4_block22_out[0][0]',      \n                                                                  'conv4_block23_3_bn[0][0]']     \n                                                                                                  \n conv4_block23_out (Activation)  (None, 8, 8, 1024)  0           ['conv4_block23_add[0][0]']      \n                                                                                                  \n conv5_block1_1_conv (Conv2D)   (None, 4, 4, 512)    524800      ['conv4_block23_out[0][0]']      \n                                                                                                  \n conv5_block1_1_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block1_1_relu (Activatio  (None, 4, 4, 512)   0           ['conv5_block1_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block1_2_conv (Conv2D)   (None, 4, 4, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n                                                                                                  \n conv5_block1_2_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block1_2_relu (Activatio  (None, 4, 4, 512)   0           ['conv5_block1_2_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block1_0_conv (Conv2D)   (None, 4, 4, 2048)   2099200     ['conv4_block23_out[0][0]']      \n                                                                                                  \n conv5_block1_3_conv (Conv2D)   (None, 4, 4, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n                                                                                                  \n conv5_block1_0_bn (BatchNormal  (None, 4, 4, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block1_3_bn (BatchNormal  (None, 4, 4, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block1_add (Add)         (None, 4, 4, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n                                                                  'conv5_block1_3_bn[0][0]']      \n                                                                                                  \n conv5_block1_out (Activation)  (None, 4, 4, 2048)   0           ['conv5_block1_add[0][0]']       \n                                                                                                  \n conv5_block2_1_conv (Conv2D)   (None, 4, 4, 512)    1049088     ['conv5_block1_out[0][0]']       \n                                                                                                  \n conv5_block2_1_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block2_1_relu (Activatio  (None, 4, 4, 512)   0           ['conv5_block2_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block2_2_conv (Conv2D)   (None, 4, 4, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n                                                                                                  \n conv5_block2_2_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block2_2_relu (Activatio  (None, 4, 4, 512)   0           ['conv5_block2_2_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block2_3_conv (Conv2D)   (None, 4, 4, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n                                                                                                  \n conv5_block2_3_bn (BatchNormal  (None, 4, 4, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block2_add (Add)         (None, 4, 4, 2048)   0           ['conv5_block1_out[0][0]',       \n                                                                  'conv5_block2_3_bn[0][0]']      \n                                                                                                  \n conv5_block2_out (Activation)  (None, 4, 4, 2048)   0           ['conv5_block2_add[0][0]']       \n                                                                                                  \n conv5_block3_1_conv (Conv2D)   (None, 4, 4, 512)    1049088     ['conv5_block2_out[0][0]']       \n                                                                                                  \n conv5_block3_1_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block3_1_relu (Activatio  (None, 4, 4, 512)   0           ['conv5_block3_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block3_2_conv (Conv2D)   (None, 4, 4, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n                                                                                                  \n conv5_block3_2_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block3_2_relu (Activatio  (None, 4, 4, 512)   0           ['conv5_block3_2_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block3_3_conv (Conv2D)   (None, 4, 4, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n                                                                                                  \n conv5_block3_3_bn (BatchNormal  (None, 4, 4, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block3_add (Add)         (None, 4, 4, 2048)   0           ['conv5_block2_out[0][0]',       \n                                                                  'conv5_block3_3_bn[0][0]']      \n                                                                                                  \n conv5_block3_out (Activation)  (None, 4, 4, 2048)   0           ['conv5_block3_add[0][0]']       \n                                                                                                  \n flatten (Flatten)              (None, 32768)        0           ['conv5_block3_out[0][0]']       \n                                                                                                  \n dense (Dense)                  (None, 1)            32769       ['flatten[0][0]']                \n                                                                                                  \n==================================================================================================\nTotal params: 42,690,945\nTrainable params: 42,585,601\nNon-trainable params: 105,344\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"tf.random.set_seed(42)\nmodel.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T11:12:52.637209Z","iopub.execute_input":"2023-05-14T11:12:52.637819Z","iopub.status.idle":"2023-05-14T11:12:52.745664Z","shell.execute_reply.started":"2023-05-14T11:12:52.637777Z","shell.execute_reply":"2023-05-14T11:12:52.744528Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    train_data,\n    validation_data=val_data,\n    epochs=100,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=3,\n            restore_best_weights=True\n        )\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T11:12:52.747045Z","iopub.execute_input":"2023-05-14T11:12:52.747433Z","iopub.status.idle":"2023-05-14T11:34:32.330087Z","shell.execute_reply.started":"2023-05-14T11:12:52.747391Z","shell.execute_reply":"2023-05-14T11:34:32.329018Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Epoch 1/100\n800/800 [==============================] - 358s 336ms/step - loss: 0.0484 - accuracy: 0.9877 - val_loss: 21.3518 - val_accuracy: 0.5205\nEpoch 2/100\n800/800 [==============================] - 189s 236ms/step - loss: 0.0110 - accuracy: 0.9970 - val_loss: 0.2359 - val_accuracy: 0.9447\nEpoch 3/100\n800/800 [==============================] - 188s 235ms/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 0.0047 - val_accuracy: 0.9986\nEpoch 4/100\n800/800 [==============================] - 188s 235ms/step - loss: 0.0182 - accuracy: 0.9950 - val_loss: 0.0930 - val_accuracy: 0.9780\nEpoch 5/100\n800/800 [==============================] - 187s 234ms/step - loss: 0.0135 - accuracy: 0.9959 - val_loss: 0.0079 - val_accuracy: 0.9983\nEpoch 6/100\n800/800 [==============================] - 188s 235ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.3084 - val_accuracy: 0.9281\n","output_type":"stream"}]},{"cell_type":"code","source":"def evaluate_model(model, test_data):\n    \n    results = model.evaluate(test_data, verbose=0)\n    loss = results[0]\n    acc = results[1]\n    \n    print(\"    Test Loss: {:.5f}\".format(loss))\n    print(\"Test Accuracy: {:.2f}%\".format(acc * 100))\n    \n    y_pred = np.squeeze((model.predict(test_data) >= 0.5).astype(np.int))\n    cm = confusion_matrix(test_data.labels, y_pred)\n    clr = classification_report(test_data.labels, y_pred, target_names=[\"NEGATIVE\", \"POSITIVE\"], digits=4)\n    \n    plt.figure(figsize=(6, 6))\n    sns.heatmap(cm, annot=True, fmt='g', vmin=0, cmap='Blues', cbar=False)\n    plt.xticks(ticks=np.arange(2) + 0.5, labels=[\"NEGATIVE\", \"POSITIVE\"])\n    plt.yticks(ticks=np.arange(2) + 0.5, labels=[\"NEGATIVE\", \"POSITIVE\"])\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Actual\")\n    plt.title(\"Confusion Matrix\")\n    plt.show()\n    \n    print(\"Classification Report:\\n----------------------\\n\", clr)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T11:34:32.331954Z","iopub.execute_input":"2023-05-14T11:34:32.332314Z","iopub.status.idle":"2023-05-14T11:34:32.342912Z","shell.execute_reply.started":"2023-05-14T11:34:32.332280Z","shell.execute_reply":"2023-05-14T11:34:32.341677Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"evaluate_model(model, test_data)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T11:34:32.344462Z","iopub.execute_input":"2023-05-14T11:34:32.345132Z","iopub.status.idle":"2023-05-14T11:36:31.590369Z","shell.execute_reply.started":"2023-05-14T11:34:32.345092Z","shell.execute_reply":"2023-05-14T11:36:31.589123Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"    Test Loss: 0.00375\nTest Accuracy: 99.91%\n250/250 [==============================] - 26s 94ms/step\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  # Remove the CWD from sys.path while we load stuff.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 600x600 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"Classification Report:\n----------------------\n               precision    recall  f1-score   support\n\n    NEGATIVE     0.9988    0.9995    0.9991      3997\n    POSITIVE     0.9995    0.9988    0.9991      4003\n\n    accuracy                         0.9991      8000\n   macro avg     0.9991    0.9991    0.9991      8000\nweighted avg     0.9991    0.9991    0.9991      8000\n\n","output_type":"stream"}]},{"cell_type":"code","source":"model.predict(test_data)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T11:36:31.592263Z","iopub.execute_input":"2023-05-14T11:36:31.592692Z","iopub.status.idle":"2023-05-14T11:36:55.819787Z","shell.execute_reply.started":"2023-05-14T11:36:31.592633Z","shell.execute_reply":"2023-05-14T11:36:55.818667Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"250/250 [==============================] - 24s 96ms/step\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"array([[1.6257899e-04],\n       [9.9999738e-01],\n       [1.4777984e-04],\n       ...,\n       [1.0000000e+00],\n       [1.5179851e-04],\n       [8.4150612e-05]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"from PIL import Image\nimport numpy as np\nfrom skimage import transform\ndef load(filename):\n   np_image = Image.open(filename)\n   np_image = np.array(np_image).astype('float32')/255\n   np_image = transform.resize(np_image, (120, 120, 3))\n   np_image = np.expand_dims(np_image, axis=0)\n   return np_image\n\nimage = load('/kaggle/input/test-img/Cracked-Concrete-Foundation.jpg')\npred = model.predict(image)\n\n\nif pred < 0.5:\n    print(\"No Crack\")\nelse:\n    print(\"Crack\")\n    ","metadata":{"execution":{"iopub.status.busy":"2023-05-14T11:37:34.091270Z","iopub.execute_input":"2023-05-14T11:37:34.091988Z","iopub.status.idle":"2023-05-14T11:37:34.245175Z","shell.execute_reply.started":"2023-05-14T11:37:34.091946Z","shell.execute_reply":"2023-05-14T11:37:34.243984Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 42ms/step\nCrack\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}